{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from Bio import pairwise2\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from Bio.Align import AlignInfo\n",
    "import pandascharm as pc\n",
    "\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from Bio.SubsMat.MatrixInfo import blosum45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeoutlier_col(df,cols):\n",
    "    Q1 = df[cols].quantile(0.25)\n",
    "    Q3 = df[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_out = df[~((df[[cols]] < (Q1 - 1.5 * IQR)) |(df[[cols]] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df_out\n",
    "\n",
    "\n",
    "def RF(X_train, y_train, X_val):\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train,np.ravel(y_train))\n",
    "    RF_pred = rf.predict(X_val)\n",
    "\n",
    "    return RF_pred\n",
    "\n",
    "def XGBR(X_train, y_train, X_val):\n",
    "    \n",
    "    model = xgb.XGBRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    XGB_pred = model.predict(X_val)\n",
    "    \n",
    "    return XGB_pred\n",
    "\n",
    "def SVM(X_train, y_train, X_val):\n",
    "    \n",
    "    model = SVR()\n",
    "    model.fit(X_train, y_train)\n",
    "    SVM_pred = model.predict(X_val)\n",
    "    \n",
    "    return SVM_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61476a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum62.update(((b,a),val) for (a,b),val in list(blosum62.items()))\n",
    "blosum45.update(((b,a),val) for (a,b),val in list(blosum45.items()))\n",
    "\n",
    "def score_pairwise(seq1, seq2, matrix, gap_s, gap_e, gap = True):\n",
    "    for A,B in zip(seq1, seq2):\n",
    "        diag = ('-'==A) or ('-'==B)\n",
    "        yield (gap_e if gap else gap_s) if diag else matrix[(A,B)]\n",
    "        gap = diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d30da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encoding, output, df_clean, aln, esm1b, key = None):\n",
    "    \n",
    "\n",
    "    ClustalAlign = AlignIO.read(aln, 'clustal')\n",
    "    summary_align = AlignInfo.SummaryInfo(ClustalAlign )\n",
    "    dframe = pc.from_bioalignment(ClustalAlign).transpose()\n",
    "    sequences = dframe.loc[df_clean.index]\n",
    "    \n",
    "    y = df_clean['Log'+output]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    \n",
    "    if encoding == 'One-Hot-Encoder':\n",
    "\n",
    "        one_hot = OneHotEncoder()\n",
    "        encoded = one_hot.fit(sequences)\n",
    "        X = encoded.transform(sequences).toarray()\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "           \n",
    "    if encoding == 'Bag-of-Words':\n",
    "\n",
    "        X = pd.DataFrame([ProteinAnalysis(i).count_amino_acids() for i in df_clean['Sequence']])\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "    if encoding == 'bigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                st = i+j\n",
    "                all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-1):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "    \n",
    "    if encoding == 'trigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    st = i+j+k\n",
    "                    all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-2):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        \n",
    "    if encoding == 'quadrogram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    for l in lst:\n",
    "                        st = i+j+k+l\n",
    "                        all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-3):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]+temp[k+3]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "    if encoding == 'BLOSUM62':\n",
    "\n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum62, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        X = np.array(enc_seq)\n",
    "        scaler.fit(enc_seq)\n",
    "        X_scaled = scaler.transform(enc_seq)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if encoding == 'BLOSUM45':\n",
    "        \n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum45, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        X = np.array(enc_seq)   \n",
    "        scaler.fit(enc_seq)\n",
    "        X_scaled = scaler.transform(enc_seq)\n",
    "        \n",
    "    if encoding == 'ESM1b':\n",
    "        \n",
    "\n",
    "        encoded = esm1b.loc[df_clean.index]\n",
    "        X = np.array(encoded)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "    return X, y, X_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9353d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance_identity_based(enzyme , df, output, aln, esm1b, methods, state):\n",
    "\n",
    "    summary=pd.DataFrame()\n",
    "    \n",
    "    df['Log'+output]=np.log10(df[output])\n",
    "    \n",
    "    df_clean = removeoutlier_col(df,'Log'+output).copy()\n",
    "    \n",
    "    # Create a mapping of unique sequences to unique codes\n",
    "    sequence_to_code = {seq: f\"ENZYME_{i+1}\" for i, seq in enumerate(df_clean['Sequence'].unique())}\n",
    "\n",
    "    # Map these codes to a new column in the DataFrame using .loc\n",
    "    df_clean.loc[:, 'Sequence Code'] = df_clean['Sequence'].map(sequence_to_code)\n",
    "    \n",
    "    df_clean = df_clean.set_index('Index')\n",
    "\n",
    "        \n",
    "    for method in methods:\n",
    "\n",
    "        X, y, X_scaled, scaler = encode(method, output, df_clean, aln, esm1b, key=None)\n",
    "        \n",
    "        splitter = GroupShuffleSplit(test_size=.20, n_splits=10, random_state = state)\n",
    "\n",
    "        split = splitter.split(df_clean, groups=df_clean['Sequence Code'])\n",
    "        \n",
    "        train_inds, val_inds = next(split)\n",
    "        \n",
    "        X_train = X[train_inds]\n",
    "        y_train = y[train_inds]\n",
    "        X_scaled_train = X_scaled[train_inds]\n",
    "        \n",
    "        \n",
    "        X_val = X[val_inds]\n",
    "        y_val = y[val_inds]\n",
    "        X_scaled_val = X_scaled[val_inds]\n",
    "\n",
    "        \n",
    "        y_predicted_RF = RF(X_train, y_train, X_val)\n",
    "        y_predicted_XGBR = XGBR(X_train, y_train, X_val)\n",
    "        y_predicted_SVM = SVM(X_scaled_train, y_train, X_scaled_val)\n",
    "\n",
    "        \n",
    "        summary['RF with ' + method] = y_predicted_RF\n",
    "        summary['XGB with ' + method] = y_predicted_XGBR\n",
    "        summary['SVM with ' + method] = y_predicted_SVM\n",
    "\n",
    "\n",
    "    X_train_seq = df_clean.loc[y_train.index]['Sequence']\n",
    "    X_val_seq = df_clean.loc[y_val.index]['Sequence']\n",
    "    max_list = []\n",
    "    \n",
    "    for sequence_val in X_val_seq:\n",
    "        score_list=[]\n",
    "        for sequence_train in X_train_seq:\n",
    "            alignment = pairwise2.align.globalxx(sequence_val, sequence_train)[0]\n",
    "            aligned_length = len(alignment.seqA)\n",
    "            identical_positions = sum(a == b for a,b in zip(alignment.seqA, alignment.seqB))\n",
    "            identity_score = (identical_positions / aligned_length)\n",
    "            score_list.append(identity_score)\n",
    "        max_list.append(max(score_list))\n",
    "\n",
    " \n",
    "    # Define the ranges\n",
    "    ranges = [(0, 0.7999), (0.80, 0.9999), (1, 1)]\n",
    "\n",
    "    # Initialize a dictionary to hold the counts for each range\n",
    "    counts = {r: 0 for r in ranges}\n",
    "\n",
    "    # Iterate through each element and determine which range it falls into\n",
    "    for element in max_list:\n",
    "        for r in ranges:\n",
    "            if r[0] <= element <= r[1]:\n",
    "                counts[r] += 1\n",
    "\n",
    "    # Print the counts for each range\n",
    "    for r in ranges:\n",
    "        print(f\"Range {r}: {counts[r]}\")\n",
    "\n",
    "    summary['y_val'] = y_val.values\n",
    "    summary['Sequence Identity'] = max_list\n",
    "    summary['wild type or mutant'] = df_clean.loc[y_val.index]['wild type or mutant'].values\n",
    "    summary=summary.set_index(y_val.index)\n",
    "\n",
    "    identity_less100 = summary[summary['Sequence Identity'] < 1] \n",
    "    identity_80 = summary[(summary['Sequence Identity'] < 0.9999) & (summary['Sequence Identity'] > 0.8)]\n",
    "    identity_0 = summary[summary['Sequence Identity'] < 0.7999]\n",
    "    identity_80_99 = summary[(summary['Sequence Identity'] <= 0.99) & (summary['Sequence Identity'] > 0.8)]\n",
    "    identity_99 = summary[summary['Sequence Identity'] > 0.99] \n",
    "\n",
    "    identity_less100_w = summary[(summary['Sequence Identity'] < 1) & (summary['wild type or mutant'] == 'wild')] \n",
    "    identity_80_w = summary[(summary['Sequence Identity'] < 0.9999) & (summary['Sequence Identity'] > 0.8) &\n",
    "                                                               (summary['wild type or mutant'] == 'wild')]\n",
    "    identity_0_w = summary[(summary['Sequence Identity'] < 0.7999) & (summary['wild type or mutant'] == 'wild')]\n",
    "    identity_80_99_w = summary[(summary['Sequence Identity'] <= 0.99) & (summary['Sequence Identity'] > 0.8) &\n",
    "                                                                      (summary['wild type or mutant'] == 'wild')]\n",
    "    identity_99_w = summary[(summary['Sequence Identity'] > 0.99) & (summary['wild type or mutant'] == 'wild')]  \n",
    "\n",
    "\n",
    "    identity_less100_m = summary[(summary['Sequence Identity'] < 1) & (summary['wild type or mutant'] == 'mutant')] \n",
    "    identity_80_m = summary[(summary['Sequence Identity'] < 0.9999) & (summary['Sequence Identity'] > 0.8) &\n",
    "                                                                    (summary['wild type or mutant'] == 'mutant')]\n",
    "    identity_99_m = summary[(summary['Sequence Identity'] > 0.99) & (summary['wild type or mutant'] == 'mutant')]  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    matrix = [identity_less100, identity_80 ,identity_0 ,identity_80_99, identity_99 ,\n",
    "              identity_less100_w, identity_80_w, identity_0_w, identity_80_99_w , identity_99_w,\n",
    "              identity_less100_m,identity_80_m,identity_99_m]\n",
    "    list_R2=[]\n",
    "\n",
    "    for identity in matrix:\n",
    "        for model in summary.columns[:-1]:\n",
    "            r2=r2_score(identity['y_val'], identity[model])\n",
    "            list_R2.append(r2)\n",
    "\n",
    "\n",
    "\n",
    "    x = np.reshape(list_R2, (len(matrix), len(summary.columns[:-1])))\n",
    "\n",
    "    number_of_data = [len(a) for a in matrix]\n",
    "\n",
    "    Results=pd.DataFrame(x, columns=summary.columns[:-1], index = ['<100%', '80-99.99%', '0-79.99%', '80-99%', '>99%',\n",
    "                                                              '<100% wild type','80-99.99% wild type', '0-79.99% wild type', '80-99% wild type', '>99% wild type',\n",
    "                                                              '<100% mutant type','80-99.99% mutant type', '>99% mutant type'])\n",
    "    Results['Number of Data'] = number_of_data\n",
    "    \n",
    "    return summary, list_R2, Results, number_of_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c25c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme = 'betaGlucosidasewithMutants'\n",
    "\n",
    "df = pd.read_excel('betaGlucosidasewithMutantsOptimumTemperature.xlsx')\n",
    "\n",
    "output = 'pNP-Glc kcat/Km (1/smM)'\n",
    "aln = enzyme + '.aln'\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "date = str(x.year)+str(x.month)+str(x.day)\n",
    "\n",
    "\n",
    "methods = ['ESM1b', 'BLOSUM45', 'BLOSUM62', 'bigram',  'quadrogram', 'Bag-of-Words']\n",
    "\n",
    "\n",
    "esm1b = pd.read_excel(enzyme+'ESM1b_embeddings.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b3a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcatKmTopt = df[df['Percentage Activity Depending on Optimum Temp']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_summary = []\n",
    "list_list_R2 = []\n",
    "list_Results = []\n",
    "random_state = [202 , 1, 42, 101, 2022,5 , 10, 22, 1995, 0]\n",
    "\n",
    "list_number_of_data = []\n",
    "\n",
    "for state in random_state:\n",
    "    summary, list_R2, Results, number_of_data = evaluate_performance_identity_based(enzyme , \n",
    "                                                                                  df_kcatKmTopt , output, aln, esm1b,\n",
    "                                                                                  methods, state)\n",
    "    print( \"Run is completed\")\n",
    "    print(Results)\n",
    "    list_summary.append(summary)\n",
    "    list_list_R2.append(list_R2)\n",
    "    list_Results.append(Results)\n",
    "    list_number_of_data.append(number_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11afc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average = pd.concat([list_Results[0],list_Results[1],list_Results[2],list_Results[3], list_Results[4],\n",
    "                       list_Results[5],list_Results[6],list_Results[7],list_Results[8], list_Results[9]])\n",
    "\n",
    "average = df_average.groupby(level=0, sort=False).mean()\n",
    "std = df_average.groupby(level=0, sort=False).std()\n",
    "list_Results.append(average)\n",
    "list_Results.append(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e38971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number_of_data = pd.DataFrame(data = list_number_of_data, columns = ['<100%', '80-99.99%', '0-79.99%', '80-99%', '>99%',\n",
    "                                                              '<100% wild type','80-99.99% wild type', '0-79.99% wild type', '80-99% wild type', '>99% wild type',\n",
    "                                                              '<100% mutant type','80-99.99% mutant type', '>99% mutant type'])\n",
    "list_Results.append(df_number_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31345bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
