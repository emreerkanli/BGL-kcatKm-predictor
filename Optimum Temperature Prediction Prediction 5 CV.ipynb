{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ee4fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\Bio\\SubsMat\\__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandascharm as pc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import blosum as bl\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from Bio.SubsMat.MatrixInfo import blosum45\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio.Align import AlignInfo\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd18a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeoutlier_col(df,cols):\n",
    "    Q1 = df[cols].quantile(0.25)\n",
    "    Q3 = df[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_out = df[~((df[[cols]] < (Q1 - 1.5 * IQR)) |(df[[cols]] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c70c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum62.update(((b,a),val) for (a,b),val in list(blosum62.items()))\n",
    "blosum45.update(((b,a),val) for (a,b),val in list(blosum45.items()))\n",
    "\n",
    "def score_pairwise(seq1, seq2, matrix, gap_s, gap_e, gap = True):\n",
    "    for A,B in zip(seq1, seq2):\n",
    "        diag = ('-'==A) or ('-'==B)\n",
    "        yield (gap_e if gap else gap_s) if diag else matrix[(A,B)]\n",
    "        gap = diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7e44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encoding, output, df_clean, aln, esm1b, key = None):\n",
    "    \n",
    "\n",
    "    ClustalAlign = AlignIO.read(aln, 'clustal')\n",
    "    summary_align = AlignInfo.SummaryInfo(ClustalAlign )\n",
    "    dframe = pc.from_bioalignment(ClustalAlign).transpose()\n",
    "    sequences = dframe.loc[df_clean.index]\n",
    "    \n",
    "    y = df_clean['y_val']\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    \n",
    "    \n",
    "    if encoding == 'One-Hot-Encoder':\n",
    "\n",
    "        one_hot = OneHotEncoder()\n",
    "        encoded = one_hot.fit(sequences)\n",
    "        X = encoded.transform(sequences).toarray()\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "           \n",
    "    if encoding == 'Bag-of-Words':\n",
    "\n",
    "        X = pd.DataFrame([ProteinAnalysis(i).count_amino_acids() for i in df_clean['Sequence']])\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "    if encoding == 'bigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                st = i+j\n",
    "                all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-1):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "    \n",
    "    if encoding == 'trigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    st = i+j+k\n",
    "                    all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-2):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        \n",
    "    if encoding == 'quadrogram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    for l in lst:\n",
    "                        st = i+j+k+l\n",
    "                        all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-3):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]+temp[k+3]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "    if encoding == 'BLOSUM62':\n",
    "\n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum62, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        X = np.array(enc_seq)\n",
    "        scaler.fit(enc_seq)\n",
    "        X_scaled = scaler.transform(enc_seq)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if encoding == 'BLOSUM45':\n",
    "        \n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum45, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        \n",
    "        X = np.array(enc_seq)   \n",
    "        scaler.fit(enc_seq)\n",
    "        X_scaled = scaler.transform(enc_seq)\n",
    "        \n",
    "    if encoding == 'ESM1b':\n",
    "        \n",
    "\n",
    "        encoded = esm1b.loc[df_clean.index]\n",
    "        X = np.array(encoded)\n",
    "        scaler.fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "    return X, y, X_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece98a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_process(encoding, output, df, aln, esm1b, temp=False):\n",
    "    \n",
    "    \n",
    "    df_clean = removeoutlier_col(df,'Log'+output).copy()\n",
    "    df_clean = df_clean.set_index('Index')\n",
    "    \n",
    "\n",
    "    X, y, X_scaled, scaler = encode(encoding, output, df_clean, aln, esm1b) \n",
    "    \n",
    "    y_scaled = y\n",
    "\n",
    "    X_scaled, y_scaled = shuffle(X_scaled, y_scaled, random_state=101)\n",
    "    \n",
    "    X, y = shuffle(X, y, random_state=101)\n",
    "    \n",
    "\n",
    "    lm = LinearRegression()   \n",
    "    scores_lm = cross_validate(lm, X_scaled, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_lm.update({\"Algorithm\": \"Linear regression\", 'Sequence Representation Method': encoding})\n",
    "                               \n",
    "    lasso_reg=Lasso()\n",
    "    scores_lasso = cross_validate(lasso_reg,  X_scaled, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_lasso.update({\"Algorithm\": \"LASSO\", 'Sequence Representation Method': encoding})\n",
    "                               \n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    scores_rf = cross_validate(rf,  X, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_rf.update({\"Algorithm\": \"Random Forest\", 'Sequence Representation Method': encoding})    \n",
    "    \n",
    "    tree_reg=DecisionTreeRegressor()\n",
    "    scores_tree_reg = cross_validate(tree_reg,  X, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_tree_reg.update({\"Algorithm\": \"Decision Tree\", 'Sequence Representation Method': encoding})    \n",
    "    \n",
    "    svr_reg = SVR()\n",
    "    scores_svr_reg = cross_validate(svr_reg,  X_scaled, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_svr_reg.update({\"Algorithm\": \"SVR\", 'Sequence Representation Method': encoding})    \n",
    "        \n",
    "    \n",
    "    mlp_reg = MLPRegressor(random_state=101, max_iter=100)\n",
    "    scores_mlp_reg = cross_validate(mlp_reg,  X_scaled, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_mlp_reg.update({\"Algorithm\": \"Neural Network\", 'Sequence Representation Method': encoding})    \n",
    "    \n",
    "    en = ElasticNet()\n",
    "    scores_en = cross_validate(en, X_scaled, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_tree_reg.update({\"Algorithm\": \"Elastic Network\", 'Sequence Representation Method': encoding})    \n",
    "    \n",
    "    xgb_reg = xgb.XGBRegressor()\n",
    "    scores_xgb_reg = cross_validate(xgb_reg,  X, y, cv=5,scoring=('r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_error'), return_train_score=True)\n",
    "    scores_xgb_reg.update({\"Algorithm\": \"XGBoost\", 'Sequence Representation Method': encoding})    \n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    dfResults = pd.concat([pd.DataFrame(scores_lm), pd.DataFrame(scores_lasso), pd.DataFrame(scores_rf), pd.DataFrame(scores_tree_reg), pd.DataFrame(scores_svr_reg), pd.DataFrame(scores_mlp_reg), pd.DataFrame(scores_tree_reg), pd.DataFrame(scores_xgb_reg)])\n",
    "        \n",
    "    \n",
    "    return dfResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb483f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme = 'betaGlucosidasewithMutants'\n",
    "\n",
    "df = pd.read_excel('betaGlucosidasewithMutantsOptimumTemperature.xlsx')\n",
    "\n",
    "output = 'pNP-Glc kcat/Km (1/smM)'\n",
    "\n",
    "methods = ['One-Hot-Encoder', 'Bag-of-Words', 'bigram', 'trigram', 'quadrogram', 'BLOSUM45', 'BLOSUM62', 'ESM1b']\n",
    "\n",
    "aln = enzyme +'.aln'\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "date = str(x.year)+str(x.month)+str(x.day)\n",
    "\n",
    "df['y_val']= df['Temperature Optimum']\n",
    "df['Log'+output]= np.log10(df[output])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb7585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "esm1b = pd.read_excel(enzyme+'ESM1b_embeddings.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db40eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kcatKmTopt = df[df['Percentage Activity Depending on Optimum Temp']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed72fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.311e+01, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.837e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.882e+02, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.592e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+02, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time       test_r2  train_r2  \\\n",
      "0   0.148213    0.005004 -1.269087e+15  0.999985   \n",
      "1   0.173395    0.005008 -3.016708e+16  0.999981   \n",
      "2   0.145682    0.005225  8.398187e-01  1.000000   \n",
      "3   0.145857    0.004519  8.394515e-01  1.000000   \n",
      "4   0.129544    0.004201 -2.100350e+18  0.999982   \n",
      "0   0.969671    0.006446  8.647216e-01  0.971121   \n",
      "1   1.077972    0.005550  7.396476e-01  0.975284   \n",
      "2   1.110911    0.005037  8.688885e-01  0.969348   \n",
      "3   1.186677    0.004004  8.493642e-01  0.972944   \n",
      "4   1.153245    0.004516  9.000625e-01  0.973217   \n",
      "0  25.456560    0.015511  8.855356e-01  0.978858   \n",
      "1  23.309983    0.017011  7.548174e-01  0.984920   \n",
      "2  25.837653    0.016331  8.716707e-01  0.978549   \n",
      "3  25.560710    0.014006  8.378595e-01  0.976872   \n",
      "4  25.556198    0.009399  9.062019e-01  0.978027   \n",
      "0   0.497184    0.004003  7.857084e-01  1.000000   \n",
      "1   0.389964    0.004224  5.580917e-01  1.000000   \n",
      "2   0.500880    0.004004  7.748061e-01  1.000000   \n",
      "3   0.477849    0.005000  7.841804e-01  1.000000   \n",
      "4   0.425976    0.005145  9.209320e-01  1.000000   \n",
      "0   0.400970    0.232134  2.317100e-01  0.266002   \n",
      "1   0.370191    0.208874  2.040389e-01  0.304966   \n",
      "2   0.338770    0.236967  2.332541e-01  0.291884   \n",
      "3   0.357478    0.217059  2.094552e-01  0.275842   \n",
      "4   0.351085    0.201022  3.951534e-01  0.273812   \n",
      "0   5.145874    0.006408 -8.436894e+00  0.910480   \n",
      "1   7.335562    0.007722 -1.331098e+01  0.964789   \n",
      "2   6.955935    0.007076 -7.206721e+00  0.915451   \n",
      "3   5.730584    0.006996 -1.085375e+01  0.935957   \n",
      "4   6.328402    0.006678 -1.490206e+01  0.930861   \n",
      "0   0.497184    0.004003  7.857084e-01  1.000000   \n",
      "1   0.389964    0.004224  5.580917e-01  1.000000   \n",
      "2   0.500880    0.004004  7.748061e-01  1.000000   \n",
      "3   0.477849    0.005000  7.841804e-01  1.000000   \n",
      "4   0.425976    0.005145  9.209320e-01  1.000000   \n",
      "0   2.001767    0.028455  8.767126e-01  1.000000   \n",
      "1   1.888672    0.027086  6.991189e-01  1.000000   \n",
      "2   1.837861    0.023774  8.851700e-01  1.000000   \n",
      "3   1.639868    0.024346  8.162269e-01  1.000000   \n",
      "4   1.744684    0.022450  8.804342e-01  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                     -1.001744e+09                      -1.063990e-01   \n",
      "1                     -4.604728e+09                      -1.186782e-01   \n",
      "2                     -1.108094e+01                      -8.307621e-13   \n",
      "3                     -1.136478e+01                      -8.193976e-13   \n",
      "4                     -3.627206e+10                      -1.188259e-01   \n",
      "0                     -1.034249e+01                      -4.611588e+00   \n",
      "1                     -1.352752e+01                      -4.324182e+00   \n",
      "2                     -1.002515e+01                      -4.778961e+00   \n",
      "3                     -1.100834e+01                      -4.450019e+00   \n",
      "4                     -7.912079e+00                      -4.551280e+00   \n",
      "0                     -9.513631e+00                      -3.945765e+00   \n",
      "1                     -1.312750e+01                      -3.377594e+00   \n",
      "2                     -9.918214e+00                      -3.997819e+00   \n",
      "3                     -1.142099e+01                      -4.114318e+00   \n",
      "4                     -7.665198e+00                      -4.122379e+00   \n",
      "0                     -1.301708e+01                      -0.000000e+00   \n",
      "1                     -1.762395e+01                      -0.000000e+00   \n",
      "2                     -1.313859e+01                      -0.000000e+00   \n",
      "3                     -1.317659e+01                      -0.000000e+00   \n",
      "4                     -7.037635e+00                      -0.000000e+00   \n",
      "0                     -2.464755e+01                      -2.324917e+01   \n",
      "1                     -2.365284e+01                      -2.293058e+01   \n",
      "2                     -2.424355e+01                      -2.296966e+01   \n",
      "3                     -2.521860e+01                      -2.302230e+01   \n",
      "4                     -1.946476e+01                      -2.369904e+01   \n",
      "0                     -8.638248e+01                      -8.119343e+00   \n",
      "1                     -1.002933e+02                      -5.161188e+00   \n",
      "2                     -7.931501e+01                      -7.937004e+00   \n",
      "3                     -9.765300e+01                      -6.846469e+00   \n",
      "4                     -9.980518e+01                      -7.312531e+00   \n",
      "0                     -1.301708e+01                      -0.000000e+00   \n",
      "1                     -1.762395e+01                      -0.000000e+00   \n",
      "2                     -1.313859e+01                      -0.000000e+00   \n",
      "3                     -1.317659e+01                      -0.000000e+00   \n",
      "4                     -7.037635e+00                      -0.000000e+00   \n",
      "0                     -9.873487e+00                      -7.898349e-03   \n",
      "1                     -1.454235e+01                      -1.281058e-02   \n",
      "2                     -9.382060e+00                      -1.166049e-02   \n",
      "3                     -1.215902e+01                      -6.805961e-03   \n",
      "4                     -8.654259e+00                      -1.131811e-02   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                 -3.443259e+08                  -1.699307e-02   \n",
      "1                 -1.781372e+09                  -1.880392e-02   \n",
      "2                 -6.296201e+00                  -6.557342e-13   \n",
      "3                 -6.421675e+00                  -5.575759e-13   \n",
      "4                 -1.191353e+10                  -2.431949e-02   \n",
      "0                 -5.876636e+00                  -3.509033e+00   \n",
      "1                 -8.222278e+00                  -3.060415e+00   \n",
      "2                 -6.806699e+00                  -3.470333e+00   \n",
      "3                 -6.946606e+00                  -3.349582e+00   \n",
      "4                 -5.221019e+00                  -3.342158e+00   \n",
      "0                 -4.566852e+00                  -2.259670e+00   \n",
      "1                 -8.092642e+00                  -1.803239e+00   \n",
      "2                 -5.537736e+00                  -2.172254e+00   \n",
      "3                 -6.205660e+00                  -2.243615e+00   \n",
      "4                 -4.460377e+00                  -2.262441e+00   \n",
      "0                 -7.111111e+00                  -0.000000e+00   \n",
      "1                 -1.067925e+01                  -0.000000e+00   \n",
      "2                 -7.830189e+00                  -0.000000e+00   \n",
      "3                 -6.754717e+00                  -0.000000e+00   \n",
      "4                 -3.641509e+00                  -0.000000e+00   \n",
      "0                 -1.462718e+01                  -1.382835e+01   \n",
      "1                 -1.455094e+01                  -1.351411e+01   \n",
      "2                 -1.420787e+01                  -1.373142e+01   \n",
      "3                 -1.643116e+01                  -1.338220e+01   \n",
      "4                 -1.170859e+01                  -1.447767e+01   \n",
      "0                 -3.461767e+01                  -3.097878e+00   \n",
      "1                 -5.307660e+01                  -2.289196e+00   \n",
      "2                 -3.941808e+01                  -3.037533e+00   \n",
      "3                 -4.339716e+01                  -3.158527e+00   \n",
      "4                 -4.732393e+01                  -2.861752e+00   \n",
      "0                 -7.111111e+00                  -0.000000e+00   \n",
      "1                 -1.067925e+01                  -0.000000e+00   \n",
      "2                 -7.830189e+00                  -0.000000e+00   \n",
      "3                 -6.754717e+00                  -0.000000e+00   \n",
      "4                 -3.641509e+00                  -0.000000e+00   \n",
      "0                 -4.697615e+00                  -3.758970e-03   \n",
      "1                 -9.132594e+00                  -5.848907e-03   \n",
      "2                 -5.451519e+00                  -5.713091e-03   \n",
      "3                 -6.579407e+00                  -3.033947e-03   \n",
      "4                 -4.976402e+00                  -6.198767e-03   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                One-Hot-Encoder  \n",
      "1  Linear regression                One-Hot-Encoder  \n",
      "2  Linear regression                One-Hot-Encoder  \n",
      "3  Linear regression                One-Hot-Encoder  \n",
      "4  Linear regression                One-Hot-Encoder  \n",
      "0              LASSO                One-Hot-Encoder  \n",
      "1              LASSO                One-Hot-Encoder  \n",
      "2              LASSO                One-Hot-Encoder  \n",
      "3              LASSO                One-Hot-Encoder  \n",
      "4              LASSO                One-Hot-Encoder  \n",
      "0      Random Forest                One-Hot-Encoder  \n",
      "1      Random Forest                One-Hot-Encoder  \n",
      "2      Random Forest                One-Hot-Encoder  \n",
      "3      Random Forest                One-Hot-Encoder  \n",
      "4      Random Forest                One-Hot-Encoder  \n",
      "0    Elastic Network                One-Hot-Encoder  \n",
      "1    Elastic Network                One-Hot-Encoder  \n",
      "2    Elastic Network                One-Hot-Encoder  \n",
      "3    Elastic Network                One-Hot-Encoder  \n",
      "4    Elastic Network                One-Hot-Encoder  \n",
      "0                SVR                One-Hot-Encoder  \n",
      "1                SVR                One-Hot-Encoder  \n",
      "2                SVR                One-Hot-Encoder  \n",
      "3                SVR                One-Hot-Encoder  \n",
      "4                SVR                One-Hot-Encoder  \n",
      "0     Neural Network                One-Hot-Encoder  \n",
      "1     Neural Network                One-Hot-Encoder  \n",
      "2     Neural Network                One-Hot-Encoder  \n",
      "3     Neural Network                One-Hot-Encoder  \n",
      "4     Neural Network                One-Hot-Encoder  \n",
      "0    Elastic Network                One-Hot-Encoder  \n",
      "1    Elastic Network                One-Hot-Encoder  \n",
      "2    Elastic Network                One-Hot-Encoder  \n",
      "3    Elastic Network                One-Hot-Encoder  \n",
      "4    Elastic Network                One-Hot-Encoder  \n",
      "0            XGBoost                One-Hot-Encoder  \n",
      "1            XGBoost                One-Hot-Encoder  \n",
      "2            XGBoost                One-Hot-Encoder  \n",
      "3            XGBoost                One-Hot-Encoder  \n",
      "4            XGBoost                One-Hot-Encoder  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time   test_r2  train_r2  test_neg_root_mean_squared_error  \\\n",
      "0  0.001229    0.001521  0.785126  0.831878                        -13.034762   \n",
      "1  0.002000    0.001000  0.751797  0.829945                        -13.208104   \n",
      "2  0.001136    0.001531  0.691705  0.848683                        -15.372818   \n",
      "3  0.002008    0.001000  0.592654  0.838266                        -18.102547   \n",
      "4  0.000211    0.001531  0.718285  0.833904                        -13.284071   \n",
      "0  0.001000    0.002000  0.748224  0.772005                        -14.109708   \n",
      "1  0.001154    0.001530  0.712152  0.770134                        -14.223914   \n",
      "2  0.001001    0.002001  0.710010  0.789829                        -14.909475   \n",
      "3  0.001702    0.002006  0.626941  0.771209                        -17.323944   \n",
      "4  0.002000    0.002000  0.702685  0.772771                        -13.646916   \n",
      "0  0.462112    0.011789  0.871046  0.981206                        -10.097849   \n",
      "1  0.400046    0.010923  0.822634  0.982354                        -11.165351   \n",
      "2  0.446239    0.010331  0.824357  0.980516                        -11.603427   \n",
      "3  0.414161    0.010491  0.856607  0.973567                        -10.740446   \n",
      "4  0.477983    0.007043  0.878770  0.978379                         -8.714265   \n",
      "0  0.004938    0.001984  0.811119  1.000000                        -12.220960   \n",
      "1  0.003856    0.001047  0.602116  1.000000                        -16.723049   \n",
      "2  0.004548    0.001299  0.597659  1.000000                        -17.561751   \n",
      "3  0.003587    0.002153  0.526895  1.000000                        -19.509069   \n",
      "4  0.004631    0.001003  0.762736  1.000000                        -12.191089   \n",
      "0  0.003875    0.003648  0.503695  0.510160                        -19.810051   \n",
      "1  0.004004    0.002517  0.436718  0.532667                        -19.897574   \n",
      "2  0.004169    0.004041  0.510781  0.540635                        -19.365202   \n",
      "3  0.004994    0.004288  0.452582  0.512216                        -20.985406   \n",
      "4  0.003781    0.003000  0.610532  0.503416                        -15.619329   \n",
      "0  0.122128    0.001552 -0.541632 -0.681055                        -34.914150   \n",
      "1  0.121442    0.002613 -0.905098 -0.548829                        -36.592831   \n",
      "2  0.117880    0.002000 -0.565260 -0.607457                        -34.638878   \n",
      "3  0.112036    0.002013 -0.719331 -0.545017                        -37.190978   \n",
      "4  0.127761    0.001997 -0.645493 -0.598919                        -32.105128   \n",
      "0  0.004938    0.001984  0.811119  1.000000                        -12.220960   \n",
      "1  0.003856    0.001047  0.602116  1.000000                        -16.723049   \n",
      "2  0.004548    0.001299  0.597659  1.000000                        -17.561751   \n",
      "3  0.003587    0.002153  0.526895  1.000000                        -19.509069   \n",
      "4  0.004631    0.001003  0.762736  1.000000                        -12.191089   \n",
      "0  0.086165    0.000000  0.858013  1.000000                        -10.595851   \n",
      "1  0.089655    0.004018  0.701633  1.000000                        -14.481462   \n",
      "2  0.069470    0.003144  0.805021  1.000000                        -12.225439   \n",
      "3  0.069194    0.003005  0.757023  1.000000                        -13.981055   \n",
      "4  0.068749    0.003266  0.854186  1.000000                         -9.557082   \n",
      "\n",
      "   train_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
      "0                         -11.126865                     -8.657856   \n",
      "1                         -11.342444                     -9.389549   \n",
      "2                         -10.618086                    -10.562670   \n",
      "3                         -10.880099                    -10.564807   \n",
      "4                         -11.334066                     -8.192450   \n",
      "0                         -12.957543                    -10.134811   \n",
      "1                         -13.187117                    -10.666908   \n",
      "2                         -12.513798                    -11.710586   \n",
      "3                         -12.940525                    -10.634952   \n",
      "4                         -13.256778                     -8.940719   \n",
      "0                          -3.720262                     -4.924630   \n",
      "1                          -3.653709                     -7.039623   \n",
      "2                          -3.810117                     -6.782075   \n",
      "3                          -4.398478                     -6.334340   \n",
      "4                          -4.089242                     -4.906792   \n",
      "0                          -0.000000                     -5.537037   \n",
      "1                          -0.000000                     -9.811321   \n",
      "2                          -0.000000                    -10.339623   \n",
      "3                          -0.000000                     -9.396226   \n",
      "4                          -0.000000                     -6.358491   \n",
      "0                         -18.992723                    -11.409761   \n",
      "1                         -18.802922                    -13.078691   \n",
      "2                         -18.500407                    -11.355208   \n",
      "3                         -18.894952                    -13.627934   \n",
      "4                         -19.597590                     -9.177278   \n",
      "0                         -35.184467                    -26.183960   \n",
      "1                         -34.230544                    -29.304559   \n",
      "2                         -34.607637                    -26.431181   \n",
      "3                         -33.627835                    -29.501042   \n",
      "4                         -35.165700                    -26.142239   \n",
      "0                          -0.000000                     -5.537037   \n",
      "1                          -0.000000                     -9.811321   \n",
      "2                          -0.000000                    -10.339623   \n",
      "3                          -0.000000                     -9.396226   \n",
      "4                          -0.000000                     -6.358491   \n",
      "0                          -0.002496                     -5.245152   \n",
      "1                          -0.002539                     -8.975742   \n",
      "2                          -0.002385                     -7.186424   \n",
      "3                          -0.001961                     -7.381909   \n",
      "4                          -0.008289                     -5.377987   \n",
      "\n",
      "   train_neg_mean_absolute_error          Algorithm  \\\n",
      "0                      -7.870772  Linear regression   \n",
      "1                      -7.617247  Linear regression   \n",
      "2                      -7.213473  Linear regression   \n",
      "3                      -7.381187  Linear regression   \n",
      "4                      -7.828868  Linear regression   \n",
      "0                      -9.797005              LASSO   \n",
      "1                      -9.164894              LASSO   \n",
      "2                      -9.148227              LASSO   \n",
      "3                      -9.503575              LASSO   \n",
      "4                      -9.605646              LASSO   \n",
      "0                      -2.247594      Random Forest   \n",
      "1                      -1.946385      Random Forest   \n",
      "2                      -2.075070      Random Forest   \n",
      "3                      -2.371643      Random Forest   \n",
      "4                      -2.239765      Random Forest   \n",
      "0                      -0.000000    Elastic Network   \n",
      "1                      -0.000000    Elastic Network   \n",
      "2                      -0.000000    Elastic Network   \n",
      "3                      -0.000000    Elastic Network   \n",
      "4                      -0.000000    Elastic Network   \n",
      "0                     -11.596094                SVR   \n",
      "1                     -11.074634                SVR   \n",
      "2                     -11.229826                SVR   \n",
      "3                     -11.116009                SVR   \n",
      "4                     -11.910145                SVR   \n",
      "0                     -27.931567     Neural Network   \n",
      "1                     -26.281553     Neural Network   \n",
      "2                     -27.586556     Neural Network   \n",
      "3                     -25.788976     Neural Network   \n",
      "4                     -27.429217     Neural Network   \n",
      "0                      -0.000000    Elastic Network   \n",
      "1                      -0.000000    Elastic Network   \n",
      "2                      -0.000000    Elastic Network   \n",
      "3                      -0.000000    Elastic Network   \n",
      "4                      -0.000000    Elastic Network   \n",
      "0                      -0.001392            XGBoost   \n",
      "1                      -0.001295            XGBoost   \n",
      "2                      -0.001289            XGBoost   \n",
      "3                      -0.001059            XGBoost   \n",
      "4                      -0.004531            XGBoost   \n",
      "\n",
      "  Sequence Representation Method  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n",
      "0                   Bag-of-Words  \n",
      "1                   Bag-of-Words  \n",
      "2                   Bag-of-Words  \n",
      "3                   Bag-of-Words  \n",
      "4                   Bag-of-Words  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fit_time  score_time       test_r2  train_r2  \\\n",
      "0  0.009331    0.002174 -1.564490e+20  0.999984   \n",
      "1  0.009243    0.002999  3.459099e-01  0.999986   \n",
      "2  0.008816    0.002001  1.269541e-01  1.000000   \n",
      "3  0.007241    0.002001  5.675034e-01  1.000000   \n",
      "4  0.006788    0.002002 -3.207982e+18  0.999986   \n",
      "0  0.006416    0.002158  8.711146e-01  0.940545   \n",
      "1  0.006005    0.002151  7.983495e-01  0.952618   \n",
      "2  0.011943    0.002089  8.231709e-01  0.945195   \n",
      "3  0.009743    0.002159  8.440528e-01  0.936787   \n",
      "4  0.008669    0.001514  8.742920e-01  0.941158   \n",
      "0  2.803657    0.011596  8.826212e-01  0.980279   \n",
      "1  2.454184    0.007895  8.155942e-01  0.980015   \n",
      "2  2.531573    0.007787  8.452119e-01  0.977051   \n",
      "3  2.599858    0.011094  8.568485e-01  0.977802   \n",
      "4  2.857418    0.008827  8.750886e-01  0.977344   \n",
      "0  0.044401    0.002507  7.739048e-01  1.000000   \n",
      "1  0.034613    0.002000  6.510798e-01  1.000000   \n",
      "2  0.030473    0.001157  7.659204e-01  1.000000   \n",
      "3  0.041644    0.003006  8.009966e-01  1.000000   \n",
      "4  0.037533    0.003001  8.060801e-01  1.000000   \n",
      "0  0.006999    0.004895  5.440824e-01  0.541264   \n",
      "1  0.005806    0.006163  4.764449e-01  0.565905   \n",
      "2  0.009211    0.008751  5.067660e-01  0.566290   \n",
      "3  0.010529    0.007574  4.888008e-01  0.548808   \n",
      "4  0.011658    0.008945  6.293937e-01  0.548408   \n",
      "0  0.305707    0.002011  8.600870e-01  0.939196   \n",
      "1  0.293161    0.002995  7.798681e-01  0.958041   \n",
      "2  0.289275    0.001985  7.910607e-01  0.947702   \n",
      "3  0.281512    0.003001  7.269178e-01  0.945345   \n",
      "4  0.291090    0.003006  7.728881e-01  0.942323   \n",
      "0  0.044401    0.002507  7.739048e-01  1.000000   \n",
      "1  0.034613    0.002000  6.510798e-01  1.000000   \n",
      "2  0.030473    0.001157  7.659204e-01  1.000000   \n",
      "3  0.041644    0.003006  8.009966e-01  1.000000   \n",
      "4  0.037533    0.003001  8.060801e-01  1.000000   \n",
      "0  0.164489    0.012509  8.741147e-01  1.000000   \n",
      "1  0.170652    0.004000  7.485726e-01  1.000000   \n",
      "2  0.159463    0.004859  8.151272e-01  1.000000   \n",
      "3  0.150603    0.004018  8.153520e-01  1.000000   \n",
      "4  0.177220    0.004200  8.701365e-01  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                     -3.517203e+11                      -1.079325e-01   \n",
      "1                     -2.144155e+01                      -1.027783e-01   \n",
      "2                     -2.586956e+01                      -9.552492e-14   \n",
      "3                     -1.865302e+01                      -5.618388e-14   \n",
      "4                     -4.482728e+10                      -1.031590e-01   \n",
      "0                     -1.009515e+01                      -6.616901e+00   \n",
      "1                     -1.190521e+01                      -5.987155e+00   \n",
      "2                     -1.164253e+01                      -6.390168e+00   \n",
      "3                     -1.120074e+01                      -6.801974e+00   \n",
      "4                     -8.873763e+00                      -6.746078e+00   \n",
      "0                     -9.633983e+00                      -3.810902e+00   \n",
      "1                     -1.138478e+01                      -3.888366e+00   \n",
      "2                     -1.089279e+01                      -4.135104e+00   \n",
      "3                     -1.073138e+01                      -4.030787e+00   \n",
      "4                     -8.845604e+00                      -4.185987e+00   \n",
      "0                     -1.337078e+01                      -0.000000e+00   \n",
      "1                     -1.566031e+01                      -0.000000e+00   \n",
      "2                     -1.339530e+01                      -0.000000e+00   \n",
      "3                     -1.265284e+01                      -0.000000e+00   \n",
      "4                     -1.102142e+01                      -0.000000e+00   \n",
      "0                     -1.898691e+01                      -1.837983e+01   \n",
      "1                     -1.918309e+01                      -1.812193e+01   \n",
      "2                     -1.944451e+01                      -1.797636e+01   \n",
      "3                     -2.027930e+01                      -1.817243e+01   \n",
      "4                     -1.523642e+01                      -1.868871e+01   \n",
      "0                     -1.051817e+01                      -6.691516e+00   \n",
      "1                     -1.243881e+01                      -5.634118e+00   \n",
      "2                     -1.265554e+01                      -6.242324e+00   \n",
      "3                     -1.482192e+01                      -6.324777e+00   \n",
      "4                     -1.192742e+01                      -6.678923e+00   \n",
      "0                     -1.337078e+01                      -0.000000e+00   \n",
      "1                     -1.566031e+01                      -0.000000e+00   \n",
      "2                     -1.339530e+01                      -0.000000e+00   \n",
      "3                     -1.265284e+01                      -0.000000e+00   \n",
      "4                     -1.102142e+01                      -0.000000e+00   \n",
      "0                     -9.976969e+00                      -1.137150e-03   \n",
      "1                     -1.329363e+01                      -1.835498e-03   \n",
      "2                     -1.190439e+01                      -1.053755e-03   \n",
      "3                     -1.218793e+01                      -1.196939e-03   \n",
      "4                     -9.019241e+00                      -2.112693e-03   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                 -1.815847e+11                  -2.921020e-02   \n",
      "1                 -1.364043e+01                  -1.408451e-02   \n",
      "2                 -1.508333e+01                  -7.255542e-14   \n",
      "3                 -1.120254e+01                  -4.196539e-14   \n",
      "4                 -2.285975e+10                  -2.218003e-02   \n",
      "0                 -6.120960e+00                  -4.854671e+00   \n",
      "1                 -7.904612e+00                  -4.106489e+00   \n",
      "2                 -8.350514e+00                  -4.338278e+00   \n",
      "3                 -7.466762e+00                  -4.686207e+00   \n",
      "4                 -5.819682e+00                  -4.774020e+00   \n",
      "0                 -4.840741e+00                  -2.354340e+00   \n",
      "1                 -7.282830e+00                  -2.106197e+00   \n",
      "2                 -6.636415e+00                  -2.242160e+00   \n",
      "3                 -6.003585e+00                  -2.254272e+00   \n",
      "4                 -5.074340e+00                  -2.342817e+00   \n",
      "0                 -7.074074e+00                  -0.000000e+00   \n",
      "1                 -9.509434e+00                  -0.000000e+00   \n",
      "2                 -7.924528e+00                  -0.000000e+00   \n",
      "3                 -6.584906e+00                  -0.000000e+00   \n",
      "4                 -5.660377e+00                  -0.000000e+00   \n",
      "0                 -1.173279e+01                  -1.138377e+01   \n",
      "1                 -1.287567e+01                  -1.097359e+01   \n",
      "2                 -1.164542e+01                  -1.117214e+01   \n",
      "3                 -1.350749e+01                  -1.098641e+01   \n",
      "4                 -9.455723e+00                  -1.163545e+01   \n",
      "0                 -6.027019e+00                  -4.130870e+00   \n",
      "1                 -7.823460e+00                  -3.371232e+00   \n",
      "2                 -8.081256e+00                  -3.520940e+00   \n",
      "3                 -7.839139e+00                  -3.719541e+00   \n",
      "4                 -7.122515e+00                  -3.846253e+00   \n",
      "0                 -7.074074e+00                  -0.000000e+00   \n",
      "1                 -9.509434e+00                  -0.000000e+00   \n",
      "2                 -7.924528e+00                  -0.000000e+00   \n",
      "3                 -6.584906e+00                  -0.000000e+00   \n",
      "4                 -5.660377e+00                  -0.000000e+00   \n",
      "0                 -5.169399e+00                  -5.750836e-04   \n",
      "1                 -9.033733e+00                  -1.003283e-03   \n",
      "2                 -6.574738e+00                  -5.380872e-04   \n",
      "3                 -6.900610e+00                  -6.369649e-04   \n",
      "4                 -4.773856e+00                  -1.263990e-03   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                         bigram  \n",
      "1  Linear regression                         bigram  \n",
      "2  Linear regression                         bigram  \n",
      "3  Linear regression                         bigram  \n",
      "4  Linear regression                         bigram  \n",
      "0              LASSO                         bigram  \n",
      "1              LASSO                         bigram  \n",
      "2              LASSO                         bigram  \n",
      "3              LASSO                         bigram  \n",
      "4              LASSO                         bigram  \n",
      "0      Random Forest                         bigram  \n",
      "1      Random Forest                         bigram  \n",
      "2      Random Forest                         bigram  \n",
      "3      Random Forest                         bigram  \n",
      "4      Random Forest                         bigram  \n",
      "0    Elastic Network                         bigram  \n",
      "1    Elastic Network                         bigram  \n",
      "2    Elastic Network                         bigram  \n",
      "3    Elastic Network                         bigram  \n",
      "4    Elastic Network                         bigram  \n",
      "0                SVR                         bigram  \n",
      "1                SVR                         bigram  \n",
      "2                SVR                         bigram  \n",
      "3                SVR                         bigram  \n",
      "4                SVR                         bigram  \n",
      "0     Neural Network                         bigram  \n",
      "1     Neural Network                         bigram  \n",
      "2     Neural Network                         bigram  \n",
      "3     Neural Network                         bigram  \n",
      "4     Neural Network                         bigram  \n",
      "0    Elastic Network                         bigram  \n",
      "1    Elastic Network                         bigram  \n",
      "2    Elastic Network                         bigram  \n",
      "3    Elastic Network                         bigram  \n",
      "4    Elastic Network                         bigram  \n",
      "0            XGBoost                         bigram  \n",
      "1            XGBoost                         bigram  \n",
      "2            XGBoost                         bigram  \n",
      "3            XGBoost                         bigram  \n",
      "4            XGBoost                         bigram  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.196e+01, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.745e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e+01, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.790e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.067e+02, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time       test_r2  train_r2  \\\n",
      "0   0.086196    0.003915 -2.814035e+16  0.999986   \n",
      "1   0.091455    0.005556 -2.236272e+17  0.999986   \n",
      "2   0.088543    0.004156  8.736899e-01  1.000000   \n",
      "3   0.092635    0.007453  8.398222e-01  1.000000   \n",
      "4   0.082895    0.004001 -1.394495e+16  0.999990   \n",
      "0   0.682630    0.005245  8.440312e-01  0.973028   \n",
      "1   0.638006    0.005291  8.159995e-01  0.973063   \n",
      "2   0.643556    0.003310  7.922528e-01  0.971218   \n",
      "3   0.408935    0.005000  7.767224e-01  0.972826   \n",
      "4   0.558797    0.005999  8.749537e-01  0.970297   \n",
      "0  16.157451    0.014952  8.863468e-01  0.978592   \n",
      "1  16.097587    0.013406  7.797457e-01  0.979256   \n",
      "2  18.372932    0.016741  8.409312e-01  0.975514   \n",
      "3  22.403757    0.010929  8.427403e-01  0.976259   \n",
      "4  21.407141    0.011881  8.604310e-01  0.977342   \n",
      "0   0.329532    0.003013  7.013970e-01  1.000000   \n",
      "1   0.279104    0.004063  6.378188e-01  1.000000   \n",
      "2   0.341547    0.003826  6.512682e-01  1.000000   \n",
      "3   0.320459    0.003006  5.357136e-01  1.000000   \n",
      "4   0.365695    0.004751  7.605069e-01  1.000000   \n",
      "0   0.224408    0.162593  3.432235e-01  0.357553   \n",
      "1   0.223766    0.161942  2.927730e-01  0.409314   \n",
      "2   0.265616    0.142401  3.331226e-01  0.385890   \n",
      "3   0.231239    0.134101  3.076177e-01  0.380052   \n",
      "4   0.231268    0.132938  4.796687e-01  0.368027   \n",
      "0   7.734682    0.006767 -5.655140e-01  0.987613   \n",
      "1   8.382892    0.006013 -2.440867e+00  0.995732   \n",
      "2   9.881401    0.007746 -1.895747e+00  0.993444   \n",
      "3  15.584510    0.017008 -2.081280e+00  0.995510   \n",
      "4  13.356431    0.007015 -2.281036e+00  0.991407   \n",
      "0   0.329532    0.003013  7.013970e-01  1.000000   \n",
      "1   0.279104    0.004063  6.378188e-01  1.000000   \n",
      "2   0.341547    0.003826  6.512682e-01  1.000000   \n",
      "3   0.320459    0.003006  5.357136e-01  1.000000   \n",
      "4   0.365695    0.004751  7.605069e-01  1.000000   \n",
      "0   1.455800    0.020999  8.683863e-01  1.000000   \n",
      "1   1.458243    0.017876  7.648932e-01  1.000000   \n",
      "2   1.152833    0.021558  7.662236e-01  1.000000   \n",
      "3   1.234065    0.015568  7.621635e-01  1.000000   \n",
      "4   1.384581    0.023514  8.484848e-01  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                     -4.717108e+09                      -1.030204e-01   \n",
      "1                     -1.253717e+10                      -1.027785e-01   \n",
      "2                     -9.839874e+00                      -8.782588e-14   \n",
      "3                     -1.135165e+01                      -1.654773e-13   \n",
      "4                     -2.955527e+09                      -8.572306e-02   \n",
      "0                     -1.110529e+01                      -4.456757e+00   \n",
      "1                     -1.137226e+01                      -4.514242e+00   \n",
      "2                     -1.261938e+01                      -4.630843e+00   \n",
      "3                     -1.340233e+01                      -4.459753e+00   \n",
      "4                     -8.850378e+00                      -4.793021e+00   \n",
      "0                     -9.479862e+00                      -3.970521e+00   \n",
      "1                     -1.244227e+01                      -3.961525e+00   \n",
      "2                     -1.104239e+01                      -4.271339e+00   \n",
      "3                     -1.124777e+01                      -4.168513e+00   \n",
      "4                     -9.350201e+00                      -4.186179e+00   \n",
      "0                     -1.536591e+01                      -0.000000e+00   \n",
      "1                     -1.595513e+01                      -0.000000e+00   \n",
      "2                     -1.634995e+01                      -0.000000e+00   \n",
      "3                     -1.932639e+01                      -0.000000e+00   \n",
      "4                     -1.224822e+01                      -0.000000e+00   \n",
      "0                     -2.278872e+01                      -2.175097e+01   \n",
      "1                     -2.229548e+01                      -2.113928e+01   \n",
      "2                     -2.260964e+01                      -2.139071e+01   \n",
      "3                     -2.360102e+01                      -2.130148e+01   \n",
      "4                     -1.805371e+01                      -2.210831e+01   \n",
      "0                     -3.518355e+01                      -3.020197e+00   \n",
      "1                     -4.917804e+01                      -1.796809e+00   \n",
      "2                     -4.711409e+01                      -2.210214e+00   \n",
      "3                     -4.978785e+01                      -1.812910e+00   \n",
      "4                     -4.533482e+01                      -2.578018e+00   \n",
      "0                     -1.536591e+01                      -0.000000e+00   \n",
      "1                     -1.595513e+01                      -0.000000e+00   \n",
      "2                     -1.634995e+01                      -0.000000e+00   \n",
      "3                     -1.932639e+01                      -0.000000e+00   \n",
      "4                     -1.224822e+01                      -0.000000e+00   \n",
      "0                     -1.020144e+01                      -9.278813e-03   \n",
      "1                     -1.285494e+01                      -5.168010e-03   \n",
      "2                     -1.338662e+01                      -4.367250e-03   \n",
      "3                     -1.383238e+01                      -1.813441e-03   \n",
      "4                     -9.742144e+00                      -1.136868e-02   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                 -2.449608e+09                  -1.424213e-02   \n",
      "1                 -7.358663e+09                  -1.421513e-02   \n",
      "2                 -6.051081e+00                  -7.398985e-14   \n",
      "3                 -6.330319e+00                  -1.408409e-13   \n",
      "4                 -1.268232e+09                  -1.595020e-02   \n",
      "0                 -6.874044e+00                  -3.328534e+00   \n",
      "1                 -7.547749e+00                  -3.192568e+00   \n",
      "2                 -8.205248e+00                  -3.221912e+00   \n",
      "3                 -7.697337e+00                  -3.268328e+00   \n",
      "4                 -5.465137e+00                  -3.389196e+00   \n",
      "0                 -4.756296e+00                  -2.332736e+00   \n",
      "1                 -7.769623e+00                  -2.197465e+00   \n",
      "2                 -6.438679e+00                  -2.275869e+00   \n",
      "3                 -6.008679e+00                  -2.299296e+00   \n",
      "4                 -5.283962e+00                  -2.299812e+00   \n",
      "0                 -7.111111e+00                  -0.000000e+00   \n",
      "1                 -9.622642e+00                  -0.000000e+00   \n",
      "2                 -9.660377e+00                  -0.000000e+00   \n",
      "3                 -1.030189e+01                  -0.000000e+00   \n",
      "4                 -6.433962e+00                  -0.000000e+00   \n",
      "0                 -1.359526e+01                  -1.303874e+01   \n",
      "1                 -1.416156e+01                  -1.254163e+01   \n",
      "2                 -1.340891e+01                  -1.288018e+01   \n",
      "3                 -1.540156e+01                  -1.249161e+01   \n",
      "4                 -1.084091e+01                  -1.337417e+01   \n",
      "0                 -1.950423e+01                  -1.453772e+00   \n",
      "1                 -3.174703e+01                  -6.999203e-01   \n",
      "2                 -2.889941e+01                  -8.430308e-01   \n",
      "3                 -2.664267e+01                  -8.282847e-01   \n",
      "4                 -2.649994e+01                  -8.933958e-01   \n",
      "0                 -7.111111e+00                  -0.000000e+00   \n",
      "1                 -9.622642e+00                  -0.000000e+00   \n",
      "2                 -9.660377e+00                  -0.000000e+00   \n",
      "3                 -1.030189e+01                  -0.000000e+00   \n",
      "4                 -6.433962e+00                  -0.000000e+00   \n",
      "0                 -4.856522e+00                  -5.108599e-03   \n",
      "1                 -7.939679e+00                  -2.624440e-03   \n",
      "2                 -7.646154e+00                  -2.331738e-03   \n",
      "3                 -7.085402e+00                  -8.915646e-04   \n",
      "4                 -5.360972e+00                  -6.742460e-03   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                        trigram  \n",
      "1  Linear regression                        trigram  \n",
      "2  Linear regression                        trigram  \n",
      "3  Linear regression                        trigram  \n",
      "4  Linear regression                        trigram  \n",
      "0              LASSO                        trigram  \n",
      "1              LASSO                        trigram  \n",
      "2              LASSO                        trigram  \n",
      "3              LASSO                        trigram  \n",
      "4              LASSO                        trigram  \n",
      "0      Random Forest                        trigram  \n",
      "1      Random Forest                        trigram  \n",
      "2      Random Forest                        trigram  \n",
      "3      Random Forest                        trigram  \n",
      "4      Random Forest                        trigram  \n",
      "0    Elastic Network                        trigram  \n",
      "1    Elastic Network                        trigram  \n",
      "2    Elastic Network                        trigram  \n",
      "3    Elastic Network                        trigram  \n",
      "4    Elastic Network                        trigram  \n",
      "0                SVR                        trigram  \n",
      "1                SVR                        trigram  \n",
      "2                SVR                        trigram  \n",
      "3                SVR                        trigram  \n",
      "4                SVR                        trigram  \n",
      "0     Neural Network                        trigram  \n",
      "1     Neural Network                        trigram  \n",
      "2     Neural Network                        trigram  \n",
      "3     Neural Network                        trigram  \n",
      "4     Neural Network                        trigram  \n",
      "0    Elastic Network                        trigram  \n",
      "1    Elastic Network                        trigram  \n",
      "2    Elastic Network                        trigram  \n",
      "3    Elastic Network                        trigram  \n",
      "4    Elastic Network                        trigram  \n",
      "0            XGBoost                        trigram  \n",
      "1            XGBoost                        trigram  \n",
      "2            XGBoost                        trigram  \n",
      "3            XGBoost                        trigram  \n",
      "4            XGBoost                        trigram  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.918e+01, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.861e+01, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.226e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.143e+01, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fit_time  score_time       test_r2  train_r2  \\\n",
      "0    4.253328    0.025769 -3.022823e+18  0.999945   \n",
      "1    4.347921    0.023195 -1.105579e+22  0.999409   \n",
      "2    4.331965    0.027459  8.585517e-01  1.000000   \n",
      "3    4.440009    0.027007  8.360326e-01  1.000000   \n",
      "4    4.309178    0.023206 -2.493125e+18  0.999830   \n",
      "0    9.760460    0.027628  8.877447e-01  0.970488   \n",
      "1   13.824501    0.024538  7.427349e-01  0.974482   \n",
      "2    5.111703    0.027642  7.339427e-01  0.970721   \n",
      "3    4.877003    0.034529  8.297794e-01  0.972333   \n",
      "4    6.378546    0.023873  8.536528e-01  0.973267   \n",
      "0  191.498959    0.057810  9.005988e-01  0.976660   \n",
      "1  172.028564    0.033063  7.415521e-01  0.980369   \n",
      "2  180.383436    0.053682  8.588252e-01  0.973924   \n",
      "3  187.313841    0.045855  8.483461e-01  0.974262   \n",
      "4  179.798134    0.054008  8.771526e-01  0.975383   \n",
      "0    3.579641    0.034123  8.625489e-01  1.000000   \n",
      "1    3.253302    0.029567  5.823052e-01  1.000000   \n",
      "2    4.282915    0.031594  8.453746e-01  1.000000   \n",
      "3    3.195290    0.032553  8.001289e-01  1.000000   \n",
      "4    4.258667    0.028499  7.989113e-01  1.000000   \n",
      "0    3.995153    7.310300  7.339187e-04  0.087585   \n",
      "1    3.998165    6.993100 -3.392104e-04  0.129587   \n",
      "2    4.209990    9.191691  1.084267e-01  0.103802   \n",
      "3    4.136024    7.764616 -9.207062e-04  0.098532   \n",
      "4    4.073583    7.480813  2.419601e-01  0.096587   \n",
      "0   30.588298    0.048386 -2.330645e+01  0.581423   \n",
      "1   47.549954    0.052595 -4.117414e+01  0.470924   \n",
      "2  121.739690    0.056966 -2.555161e+01  0.635603   \n",
      "3  108.414454    0.055397 -2.568033e+01  0.449418   \n",
      "4   80.281974    0.054705 -3.914615e+01  0.694512   \n",
      "0    3.579641    0.034123  8.625489e-01  1.000000   \n",
      "1    3.253302    0.029567  5.823052e-01  1.000000   \n",
      "2    4.282915    0.031594  8.453746e-01  1.000000   \n",
      "3    3.195290    0.032553  8.001289e-01  1.000000   \n",
      "4    4.258667    0.028499  7.989113e-01  1.000000   \n",
      "0   47.402672    0.423967  9.182920e-01  0.999998   \n",
      "1   35.792079    0.355221  6.800989e-01  1.000000   \n",
      "2   35.341784    0.374702  8.901431e-01  0.999999   \n",
      "3   35.003152    0.360717  8.320464e-01  1.000000   \n",
      "4   38.530508    0.378787  8.591048e-01  0.999999   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                     -4.888971e+10                      -2.016302e-01   \n",
      "1                     -2.787611e+12                      -6.685161e-01   \n",
      "2                     -1.041284e+01                      -2.279676e-12   \n",
      "3                     -1.148514e+01                      -3.079383e-12   \n",
      "4                     -3.951831e+10                      -3.624756e-01   \n",
      "0                     -9.421379e+00                      -4.661827e+00   \n",
      "1                     -1.344707e+01                      -4.393727e+00   \n",
      "2                     -1.428098e+01                      -4.670675e+00   \n",
      "3                     -1.170210e+01                      -4.499989e+00   \n",
      "4                     -9.574557e+00                      -4.547075e+00   \n",
      "0                     -8.865578e+00                      -4.145800e+00   \n",
      "1                     -1.347795e+01                      -3.853709e+00   \n",
      "2                     -1.040277e+01                      -4.407801e+00   \n",
      "3                     -1.104548e+01                      -4.340327e+00   \n",
      "4                     -8.772218e+00                      -4.363352e+00   \n",
      "0                     -1.042522e+01                      -0.000000e+00   \n",
      "1                     -1.713432e+01                      -0.000000e+00   \n",
      "2                     -1.088707e+01                      -0.000000e+00   \n",
      "3                     -1.268040e+01                      -0.000000e+00   \n",
      "4                     -1.122329e+01                      -0.000000e+00   \n",
      "0                     -2.810941e+01                      -2.592128e+01   \n",
      "1                     -2.651618e+01                      -2.566107e+01   \n",
      "2                     -2.614262e+01                      -2.584070e+01   \n",
      "3                     -2.837642e+01                      -2.568664e+01   \n",
      "4                     -2.179076e+01                      -2.643316e+01   \n",
      "0                     -1.386347e+02                      -1.755689e+01   \n",
      "1                     -1.721712e+02                      -2.000651e+01   \n",
      "2                     -1.426645e+02                      -1.647743e+01   \n",
      "3                     -1.465053e+02                      -2.007442e+01   \n",
      "4                     -1.585800e+02                      -1.537104e+01   \n",
      "0                     -1.042522e+01                      -0.000000e+00   \n",
      "1                     -1.713432e+01                      -0.000000e+00   \n",
      "2                     -1.088707e+01                      -0.000000e+00   \n",
      "3                     -1.268040e+01                      -0.000000e+00   \n",
      "4                     -1.122329e+01                      -0.000000e+00   \n",
      "0                     -8.037914e+00                      -3.849708e-02   \n",
      "1                     -1.499496e+01                      -1.526956e-02   \n",
      "2                     -9.176649e+00                      -2.622044e-02   \n",
      "3                     -1.162391e+01                      -1.814646e-02   \n",
      "4                     -9.394518e+00                      -2.918779e-02   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                 -2.364538e+10                  -8.454202e-02   \n",
      "1                 -7.908949e+11                  -2.962250e-01   \n",
      "2                 -5.876392e+00                  -1.433812e-12   \n",
      "3                 -6.180964e+00                  -2.774419e-12   \n",
      "4                 -1.848935e+10                  -1.793107e-01   \n",
      "0                 -5.871160e+00                  -3.637664e+00   \n",
      "1                 -8.982056e+00                  -3.220786e+00   \n",
      "2                 -8.152370e+00                  -3.585037e+00   \n",
      "3                 -7.204124e+00                  -3.423451e+00   \n",
      "4                 -6.541662e+00                  -3.523365e+00   \n",
      "0                 -4.196111e+00                  -2.380519e+00   \n",
      "1                 -8.043396e+00                  -2.022488e+00   \n",
      "2                 -5.540943e+00                  -2.336854e+00   \n",
      "3                 -6.168113e+00                  -2.281690e+00   \n",
      "4                 -4.908491e+00                  -2.319812e+00   \n",
      "0                 -5.203704e+00                  -0.000000e+00   \n",
      "1                 -9.886792e+00                  -0.000000e+00   \n",
      "2                 -6.301887e+00                  -0.000000e+00   \n",
      "3                 -6.943396e+00                  -0.000000e+00   \n",
      "4                 -5.773585e+00                  -0.000000e+00   \n",
      "0                 -1.660304e+01                  -1.517033e+01   \n",
      "1                 -1.628960e+01                  -1.478139e+01   \n",
      "2                 -1.502542e+01                  -1.524604e+01   \n",
      "3                 -1.804455e+01                  -1.469317e+01   \n",
      "4                 -1.304999e+01                  -1.609960e+01   \n",
      "0                 -7.147585e+01                  -1.034376e+01   \n",
      "1                 -1.134355e+02                  -7.657103e+00   \n",
      "2                 -9.006705e+01                  -5.089117e+00   \n",
      "3                 -7.644901e+01                  -6.905555e+00   \n",
      "4                 -9.156227e+01                  -6.355403e+00   \n",
      "0                 -5.203704e+00                  -0.000000e+00   \n",
      "1                 -9.886792e+00                  -0.000000e+00   \n",
      "2                 -6.301887e+00                  -0.000000e+00   \n",
      "3                 -6.943396e+00                  -0.000000e+00   \n",
      "4                 -5.773585e+00                  -0.000000e+00   \n",
      "0                 -3.792345e+00                  -2.601877e-02   \n",
      "1                 -9.229554e+00                  -8.666347e-03   \n",
      "2                 -4.966437e+00                  -1.602981e-02   \n",
      "3                 -6.196416e+00                  -1.104546e-02   \n",
      "4                 -5.317049e+00                  -1.749796e-02   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                     quadrogram  \n",
      "1  Linear regression                     quadrogram  \n",
      "2  Linear regression                     quadrogram  \n",
      "3  Linear regression                     quadrogram  \n",
      "4  Linear regression                     quadrogram  \n",
      "0              LASSO                     quadrogram  \n",
      "1              LASSO                     quadrogram  \n",
      "2              LASSO                     quadrogram  \n",
      "3              LASSO                     quadrogram  \n",
      "4              LASSO                     quadrogram  \n",
      "0      Random Forest                     quadrogram  \n",
      "1      Random Forest                     quadrogram  \n",
      "2      Random Forest                     quadrogram  \n",
      "3      Random Forest                     quadrogram  \n",
      "4      Random Forest                     quadrogram  \n",
      "0    Elastic Network                     quadrogram  \n",
      "1    Elastic Network                     quadrogram  \n",
      "2    Elastic Network                     quadrogram  \n",
      "3    Elastic Network                     quadrogram  \n",
      "4    Elastic Network                     quadrogram  \n",
      "0                SVR                     quadrogram  \n",
      "1                SVR                     quadrogram  \n",
      "2                SVR                     quadrogram  \n",
      "3                SVR                     quadrogram  \n",
      "4                SVR                     quadrogram  \n",
      "0     Neural Network                     quadrogram  \n",
      "1     Neural Network                     quadrogram  \n",
      "2     Neural Network                     quadrogram  \n",
      "3     Neural Network                     quadrogram  \n",
      "4     Neural Network                     quadrogram  \n",
      "0    Elastic Network                     quadrogram  \n",
      "1    Elastic Network                     quadrogram  \n",
      "2    Elastic Network                     quadrogram  \n",
      "3    Elastic Network                     quadrogram  \n",
      "4    Elastic Network                     quadrogram  \n",
      "0            XGBoost                     quadrogram  \n",
      "1            XGBoost                     quadrogram  \n",
      "2            XGBoost                     quadrogram  \n",
      "3            XGBoost                     quadrogram  \n",
      "4            XGBoost                     quadrogram  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.808e+01, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.293e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.169e+01, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.606e+01, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+02, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e+02, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.261e+02, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+02, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.685e+02, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time     test_r2  train_r2  \\\n",
      "0   0.016668    0.003690  -43.561864  0.999985   \n",
      "1   0.007679    0.001517 -239.173040  0.999981   \n",
      "2   0.010694    0.002999  -45.756963  1.000000   \n",
      "3   0.010700    0.003006  -81.063410  1.000000   \n",
      "4   0.008935    0.003073 -376.424457  0.999982   \n",
      "0   0.028097    0.003008    0.840855  0.838534   \n",
      "1   0.040814    0.003215    0.786557  0.861197   \n",
      "2   0.039410    0.001997    0.750829  0.844937   \n",
      "3   0.048183    0.003687    0.757203  0.830191   \n",
      "4   0.040454    0.001995    0.844888  0.842782   \n",
      "0   8.414856    0.009822    0.884231  0.978414   \n",
      "1   7.430734    0.011763    0.768752  0.982324   \n",
      "2   7.355283    0.008543    0.879162  0.978189   \n",
      "3  10.695660    0.017568    0.826342  0.977058   \n",
      "4   9.935907    0.022396    0.850153  0.976304   \n",
      "0   0.159788    0.003339    0.633995  1.000000   \n",
      "1   0.155067    0.003491    0.669978  1.000000   \n",
      "2   0.116379    0.003019    0.815395  1.000000   \n",
      "3   0.131928    0.002013    0.857684  1.000000   \n",
      "4   0.143455    0.002998    0.725115  1.000000   \n",
      "0   0.011010    0.010010    0.606075  0.572523   \n",
      "1   0.011725    0.009047    0.546718  0.584947   \n",
      "2   0.012293    0.008759    0.533437  0.619341   \n",
      "3   0.009324    0.008301    0.511354  0.573979   \n",
      "4   0.008998    0.006001    0.667446  0.602930   \n",
      "0   0.314992    0.003476    0.771525  0.811844   \n",
      "1   0.350178    0.003999    0.754467  0.829098   \n",
      "2   0.314473    0.004000    0.747377  0.825874   \n",
      "3   0.367942    0.003706    0.721670  0.817032   \n",
      "4   0.370715    0.004513    0.792923  0.804621   \n",
      "0   0.159788    0.003339    0.633995  1.000000   \n",
      "1   0.155067    0.003491    0.669978  1.000000   \n",
      "2   0.116379    0.003019    0.815395  1.000000   \n",
      "3   0.131928    0.002013    0.857684  1.000000   \n",
      "4   0.143455    0.002998    0.725115  1.000000   \n",
      "0   1.340138    0.006505    0.829022  1.000000   \n",
      "1   1.171299    0.005462    0.785714  1.000000   \n",
      "2   1.485293    0.011453    0.881048  1.000000   \n",
      "3   1.620173    0.011103    0.792253  1.000000   \n",
      "4   2.172625    0.004655    0.860239  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                       -187.712329                      -1.063990e-01   \n",
      "1                       -410.865268                      -1.186782e-01   \n",
      "2                       -189.318780                      -1.502850e-12   \n",
      "3                       -256.940502                      -1.836208e-12   \n",
      "4                       -486.229648                      -1.188250e-01   \n",
      "0                        -11.217812                      -1.090438e+01   \n",
      "1                        -12.248373                      -1.024735e+01   \n",
      "2                        -13.820349                      -1.074873e+01   \n",
      "3                        -13.975901                      -1.114840e+01   \n",
      "4                         -9.857101                      -1.102700e+01   \n",
      "0                         -9.567707                      -3.986990e+00   \n",
      "1                        -12.749018                      -3.656840e+00   \n",
      "2                         -9.624376                      -4.031299e+00   \n",
      "3                        -11.819652                      -4.097740e+00   \n",
      "4                         -9.688378                      -4.281005e+00   \n",
      "0                        -17.011978                      -0.000000e+00   \n",
      "1                        -15.230307                      -0.000000e+00   \n",
      "2                        -11.895774                      -0.000000e+00   \n",
      "3                        -10.700026                      -0.000000e+00   \n",
      "4                        -13.122068                      -0.000000e+00   \n",
      "0                        -17.648901                      -1.774256e+01   \n",
      "1                        -17.849307                      -1.772000e+01   \n",
      "2                        -18.911491                      -1.684110e+01   \n",
      "3                        -19.826915                      -1.765825e+01   \n",
      "4                        -14.433029                      -1.752425e+01   \n",
      "0                        -13.440952                      -1.177115e+01   \n",
      "1                        -13.136879                      -1.137067e+01   \n",
      "2                        -13.915750                      -1.139028e+01   \n",
      "3                        -14.963667                      -1.157231e+01   \n",
      "4                        -11.389177                      -1.229265e+01   \n",
      "0                        -17.011978                      -0.000000e+00   \n",
      "1                        -15.230307                      -0.000000e+00   \n",
      "2                        -11.895774                      -0.000000e+00   \n",
      "3                        -10.700026                      -0.000000e+00   \n",
      "4                        -13.122068                      -0.000000e+00   \n",
      "0                        -11.627357                      -4.420682e-03   \n",
      "1                        -12.272539                      -2.029513e-03   \n",
      "2                         -9.548970                      -2.331413e-03   \n",
      "3                        -12.927820                      -2.950954e-03   \n",
      "4                         -9.356639                      -3.698512e-03   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                    -71.233169                  -1.698113e-02   \n",
      "1                   -187.210330                  -1.877934e-02   \n",
      "2                    -97.844125                  -9.841517e-13   \n",
      "3                   -103.415867                  -1.311635e-12   \n",
      "4                   -224.299087                  -2.398550e-02   \n",
      "0                     -7.786880                  -7.881967e+00   \n",
      "1                     -8.983555                  -7.291338e+00   \n",
      "2                     -9.035961                  -7.735272e+00   \n",
      "3                     -9.715200                  -7.831970e+00   \n",
      "4                     -7.205745                  -7.879372e+00   \n",
      "0                     -4.682963                  -2.315896e+00   \n",
      "1                     -7.520000                  -1.984789e+00   \n",
      "2                     -5.790943                  -2.241925e+00   \n",
      "3                     -6.204528                  -2.119249e+00   \n",
      "4                     -5.690000                  -2.343662e+00   \n",
      "0                     -8.703704                  -0.000000e+00   \n",
      "1                     -9.811321                  -0.000000e+00   \n",
      "2                     -6.301887                  -0.000000e+00   \n",
      "3                     -5.547170                  -0.000000e+00   \n",
      "4                     -5.962264                  -0.000000e+00   \n",
      "0                    -11.481314                  -1.135758e+01   \n",
      "1                    -11.820951                  -1.128704e+01   \n",
      "2                    -11.811539                  -1.089193e+01   \n",
      "3                    -13.630611                  -1.101828e+01   \n",
      "4                     -9.212677                  -1.138786e+01   \n",
      "0                     -8.333713                  -7.260007e+00   \n",
      "1                     -8.918929                  -6.998973e+00   \n",
      "2                     -8.284546                  -7.208513e+00   \n",
      "3                     -8.816608                  -7.122074e+00   \n",
      "4                     -6.952944                  -7.654652e+00   \n",
      "0                     -8.703704                  -0.000000e+00   \n",
      "1                     -9.811321                  -0.000000e+00   \n",
      "2                     -6.301887                  -0.000000e+00   \n",
      "3                     -5.547170                  -0.000000e+00   \n",
      "4                     -5.962264                  -0.000000e+00   \n",
      "0                     -6.116564                  -3.075006e-03   \n",
      "1                     -8.381867                  -1.233974e-03   \n",
      "2                     -5.821834                  -1.498334e-03   \n",
      "3                     -7.195817                  -2.109223e-03   \n",
      "4                     -5.188839                  -2.668085e-03   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                       BLOSUM45  \n",
      "1  Linear regression                       BLOSUM45  \n",
      "2  Linear regression                       BLOSUM45  \n",
      "3  Linear regression                       BLOSUM45  \n",
      "4  Linear regression                       BLOSUM45  \n",
      "0              LASSO                       BLOSUM45  \n",
      "1              LASSO                       BLOSUM45  \n",
      "2              LASSO                       BLOSUM45  \n",
      "3              LASSO                       BLOSUM45  \n",
      "4              LASSO                       BLOSUM45  \n",
      "0      Random Forest                       BLOSUM45  \n",
      "1      Random Forest                       BLOSUM45  \n",
      "2      Random Forest                       BLOSUM45  \n",
      "3      Random Forest                       BLOSUM45  \n",
      "4      Random Forest                       BLOSUM45  \n",
      "0    Elastic Network                       BLOSUM45  \n",
      "1    Elastic Network                       BLOSUM45  \n",
      "2    Elastic Network                       BLOSUM45  \n",
      "3    Elastic Network                       BLOSUM45  \n",
      "4    Elastic Network                       BLOSUM45  \n",
      "0                SVR                       BLOSUM45  \n",
      "1                SVR                       BLOSUM45  \n",
      "2                SVR                       BLOSUM45  \n",
      "3                SVR                       BLOSUM45  \n",
      "4                SVR                       BLOSUM45  \n",
      "0     Neural Network                       BLOSUM45  \n",
      "1     Neural Network                       BLOSUM45  \n",
      "2     Neural Network                       BLOSUM45  \n",
      "3     Neural Network                       BLOSUM45  \n",
      "4     Neural Network                       BLOSUM45  \n",
      "0    Elastic Network                       BLOSUM45  \n",
      "1    Elastic Network                       BLOSUM45  \n",
      "2    Elastic Network                       BLOSUM45  \n",
      "3    Elastic Network                       BLOSUM45  \n",
      "4    Elastic Network                       BLOSUM45  \n",
      "0            XGBoost                       BLOSUM45  \n",
      "1            XGBoost                       BLOSUM45  \n",
      "2            XGBoost                       BLOSUM45  \n",
      "3            XGBoost                       BLOSUM45  \n",
      "4            XGBoost                       BLOSUM45  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.746e+01, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.607e+01, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.383e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.769e+01, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.035e+02, tolerance: 1.561e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+02, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+02, tolerance: 1.587e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e+02, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.743e+02, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time     test_r2  train_r2  \\\n",
      "0   0.012751    0.002537  -37.303434  0.999985   \n",
      "1   0.008542    0.002705 -152.830118  0.999981   \n",
      "2   0.010721    0.003000  -63.656297  1.000000   \n",
      "3   0.010281    0.003520 -222.567550  1.000000   \n",
      "4   0.011858    0.003516 -375.656448  0.999982   \n",
      "0   0.043717    0.003000    0.836898  0.836371   \n",
      "1   0.046891    0.002056    0.785462  0.858854   \n",
      "2   0.052397    0.002997    0.749465  0.843325   \n",
      "3   0.048112    0.003240    0.751645  0.828314   \n",
      "4   0.047926    0.004002    0.841440  0.839607   \n",
      "0  10.814011    0.014998    0.870906  0.980727   \n",
      "1   8.479193    0.009774    0.773577  0.981942   \n",
      "2   8.812259    0.013372    0.880043  0.976373   \n",
      "3   8.888094    0.010360    0.832831  0.978977   \n",
      "4   8.852528    0.012930    0.850588  0.978432   \n",
      "0   0.127477    0.002001    0.770509  1.000000   \n",
      "1   0.086553    0.003002    0.585607  1.000000   \n",
      "2   0.091387    0.003006    0.801020  1.000000   \n",
      "3   0.108360    0.001995    0.823207  1.000000   \n",
      "4   0.115835    0.002002    0.580232  1.000000   \n",
      "0   0.008779    0.007001    0.603842  0.569972   \n",
      "1   0.007518    0.004854    0.543118  0.581239   \n",
      "2   0.006821    0.005000    0.531845  0.617459   \n",
      "3   0.008609    0.003720    0.511533  0.574210   \n",
      "4   0.005999    0.007398    0.665162  0.600882   \n",
      "0   0.277970    0.003008    0.772184  0.809072   \n",
      "1   0.318134    0.003193    0.754727  0.826920   \n",
      "2   0.337081    0.002513    0.742615  0.824842   \n",
      "3   0.266009    0.003007    0.723560  0.815430   \n",
      "4   0.285065    0.002000    0.788858  0.802230   \n",
      "0   0.127477    0.002001    0.770509  1.000000   \n",
      "1   0.086553    0.003002    0.585607  1.000000   \n",
      "2   0.091387    0.003006    0.801020  1.000000   \n",
      "3   0.108360    0.001995    0.823207  1.000000   \n",
      "4   0.115835    0.002002    0.580232  1.000000   \n",
      "0   0.777534    0.004103    0.870901  1.000000   \n",
      "1   0.712146    0.005001    0.764333  1.000000   \n",
      "2   0.874187    0.005232    0.873650  1.000000   \n",
      "3   0.834239    0.004003    0.773341  1.000000   \n",
      "4   0.798290    0.004001    0.869263  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                       -174.032348                      -1.063990e-01   \n",
      "1                       -328.819821                      -1.186782e-01   \n",
      "2                       -222.626043                      -2.185944e-12   \n",
      "3                       -424.094042                      -2.278493e-12   \n",
      "4                       -485.734690                      -1.188250e-01   \n",
      "0                        -11.356404                      -1.097716e+01   \n",
      "1                        -12.279761                      -1.033346e+01   \n",
      "2                        -13.858135                      -1.080443e+01   \n",
      "3                        -14.134942                      -1.120984e+01   \n",
      "4                         -9.966060                      -1.113778e+01   \n",
      "0                        -10.103310                      -3.767334e+00   \n",
      "1                        -12.615286                      -3.696126e+00   \n",
      "2                         -9.589203                      -4.195741e+00   \n",
      "3                        -11.596730                      -3.922683e+00   \n",
      "4                         -9.674288                      -4.084241e+00   \n",
      "0                        -13.470819                      -0.000000e+00   \n",
      "1                        -17.066463                      -0.000000e+00   \n",
      "2                        -12.350235                      -0.000000e+00   \n",
      "3                        -11.925872                      -0.000000e+00   \n",
      "4                        -16.215529                      -0.000000e+00   \n",
      "0                        -17.698857                      -1.779543e+01   \n",
      "1                        -17.920049                      -1.779897e+01   \n",
      "2                        -18.943725                      -1.688269e+01   \n",
      "3                        -19.823271                      -1.765345e+01   \n",
      "4                        -14.482503                      -1.756940e+01   \n",
      "0                        -13.421577                      -1.185755e+01   \n",
      "1                        -13.129936                      -1.144288e+01   \n",
      "2                        -14.046319                      -1.142397e+01   \n",
      "3                        -14.912767                      -1.162286e+01   \n",
      "4                        -11.500409                      -1.236761e+01   \n",
      "0                        -13.470819                      -0.000000e+00   \n",
      "1                        -17.066463                      -0.000000e+00   \n",
      "2                        -12.350235                      -0.000000e+00   \n",
      "3                        -11.925872                      -0.000000e+00   \n",
      "4                        -16.215529                      -0.000000e+00   \n",
      "0                        -10.103526                      -5.069038e-03   \n",
      "1                        -12.870239                      -2.864196e-03   \n",
      "2                         -9.841448                      -2.768703e-03   \n",
      "3                        -13.503429                      -5.619881e-03   \n",
      "4                         -9.049513                      -3.165926e-03   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                    -64.742668                  -1.698113e-02   \n",
      "1                   -171.900424                  -1.877934e-02   \n",
      "2                   -102.318406                  -1.499145e-12   \n",
      "3                   -151.601224                  -1.749803e-12   \n",
      "4                   -219.704303                  -2.398550e-02   \n",
      "0                     -7.878796                  -7.951258e+00   \n",
      "1                     -8.966576                  -7.373821e+00   \n",
      "2                     -9.100781                  -7.791100e+00   \n",
      "3                     -9.835009                  -7.886048e+00   \n",
      "4                     -7.350660                  -7.967122e+00   \n",
      "0                     -5.059815                  -2.162264e+00   \n",
      "1                     -7.445849                  -2.023286e+00   \n",
      "2                     -5.602075                  -2.294836e+00   \n",
      "3                     -6.020755                  -2.094131e+00   \n",
      "4                     -5.556226                  -2.203662e+00   \n",
      "0                     -6.388889                  -0.000000e+00   \n",
      "1                    -10.471698                  -0.000000e+00   \n",
      "2                     -7.773585                  -0.000000e+00   \n",
      "3                     -6.377358                  -0.000000e+00   \n",
      "4                     -8.867925                  -0.000000e+00   \n",
      "0                    -11.494147                  -1.139342e+01   \n",
      "1                    -11.843955                  -1.133304e+01   \n",
      "2                    -11.841138                  -1.091633e+01   \n",
      "3                    -13.628548                  -1.102473e+01   \n",
      "4                     -9.249600                  -1.141424e+01   \n",
      "0                     -8.301229                  -7.284058e+00   \n",
      "1                     -8.876879                  -6.997166e+00   \n",
      "2                     -8.312255                  -7.201029e+00   \n",
      "3                     -8.779113                  -7.154021e+00   \n",
      "4                     -6.968215                  -7.662401e+00   \n",
      "0                     -6.388889                  -0.000000e+00   \n",
      "1                    -10.471698                  -0.000000e+00   \n",
      "2                     -7.773585                  -0.000000e+00   \n",
      "3                     -6.377358                  -0.000000e+00   \n",
      "4                     -8.867925                  -0.000000e+00   \n",
      "0                     -5.280620                  -3.396601e-03   \n",
      "1                     -8.635440                  -1.777291e-03   \n",
      "2                     -5.678237                  -1.846081e-03   \n",
      "3                     -7.536187                  -4.006014e-03   \n",
      "4                     -5.304538                  -2.033037e-03   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                       BLOSUM62  \n",
      "1  Linear regression                       BLOSUM62  \n",
      "2  Linear regression                       BLOSUM62  \n",
      "3  Linear regression                       BLOSUM62  \n",
      "4  Linear regression                       BLOSUM62  \n",
      "0              LASSO                       BLOSUM62  \n",
      "1              LASSO                       BLOSUM62  \n",
      "2              LASSO                       BLOSUM62  \n",
      "3              LASSO                       BLOSUM62  \n",
      "4              LASSO                       BLOSUM62  \n",
      "0      Random Forest                       BLOSUM62  \n",
      "1      Random Forest                       BLOSUM62  \n",
      "2      Random Forest                       BLOSUM62  \n",
      "3      Random Forest                       BLOSUM62  \n",
      "4      Random Forest                       BLOSUM62  \n",
      "0    Elastic Network                       BLOSUM62  \n",
      "1    Elastic Network                       BLOSUM62  \n",
      "2    Elastic Network                       BLOSUM62  \n",
      "3    Elastic Network                       BLOSUM62  \n",
      "4    Elastic Network                       BLOSUM62  \n",
      "0                SVR                       BLOSUM62  \n",
      "1                SVR                       BLOSUM62  \n",
      "2                SVR                       BLOSUM62  \n",
      "3                SVR                       BLOSUM62  \n",
      "4                SVR                       BLOSUM62  \n",
      "0     Neural Network                       BLOSUM62  \n",
      "1     Neural Network                       BLOSUM62  \n",
      "2     Neural Network                       BLOSUM62  \n",
      "3     Neural Network                       BLOSUM62  \n",
      "4     Neural Network                       BLOSUM62  \n",
      "0    Elastic Network                       BLOSUM62  \n",
      "1    Elastic Network                       BLOSUM62  \n",
      "2    Elastic Network                       BLOSUM62  \n",
      "3    Elastic Network                       BLOSUM62  \n",
      "4    Elastic Network                       BLOSUM62  \n",
      "0            XGBoost                       BLOSUM62  \n",
      "1            XGBoost                       BLOSUM62  \n",
      "2            XGBoost                       BLOSUM62  \n",
      "3            XGBoost                       BLOSUM62  \n",
      "4            XGBoost                       BLOSUM62  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+01, tolerance: 1.611e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+01, tolerance: 1.559e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\memre\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.054e+01, tolerance: 1.647e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time   test_r2  train_r2  \\\n",
      "0   0.029880    0.003507  0.509915  1.000000   \n",
      "1   0.022005    0.003000  0.507448  1.000000   \n",
      "2   0.021594    0.003012  0.083561  1.000000   \n",
      "3   0.022897    0.004004 -0.198673  1.000000   \n",
      "4   0.023216    0.002999 -0.645508  1.000000   \n",
      "0   0.062406    0.003000  0.883292  0.911950   \n",
      "1   0.076813    0.002000  0.853662  0.919928   \n",
      "2   0.060511    0.001998  0.853307  0.917462   \n",
      "3   0.075875    0.003000  0.855033  0.918782   \n",
      "4   0.049929    0.002012  0.834478  0.909860   \n",
      "0  44.128869    0.017402  0.903529  0.983782   \n",
      "1  42.851969    0.018085  0.851411  0.984813   \n",
      "2  48.703778    0.012122  0.883557  0.982791   \n",
      "3  45.604509    0.012861  0.893718  0.983596   \n",
      "4  43.906337    0.008528  0.892061  0.983200   \n",
      "0   0.598464    0.004002  0.798332  1.000000   \n",
      "1   0.553771    0.002227  0.781999  1.000000   \n",
      "2   0.633530    0.004794  0.793439  1.000000   \n",
      "3   0.531534    0.002601  0.800340  1.000000   \n",
      "4   0.620675    0.005445  0.819303  1.000000   \n",
      "0   0.031443    0.017004  0.714737  0.692444   \n",
      "1   0.027145    0.022884  0.671419  0.712031   \n",
      "2   0.037407    0.017757  0.687877  0.723798   \n",
      "3   0.036717    0.018680  0.623641  0.686658   \n",
      "4   0.036193    0.021439  0.735203  0.715202   \n",
      "0   1.572544    0.005816  0.913317  0.936951   \n",
      "1   1.576586    0.005331  0.785589  0.947771   \n",
      "2   1.512637    0.003990  0.891695  0.939210   \n",
      "3   1.348454    0.005009  0.832000  0.948740   \n",
      "4   1.332500    0.002990  0.783771  0.941529   \n",
      "0   0.598464    0.004002  0.798332  1.000000   \n",
      "1   0.553771    0.002227  0.781999  1.000000   \n",
      "2   0.633530    0.004794  0.793439  1.000000   \n",
      "3   0.531534    0.002601  0.800340  1.000000   \n",
      "4   0.620675    0.005445  0.819303  1.000000   \n",
      "0   6.553696    0.014518  0.869391  1.000000   \n",
      "1   6.708725    0.000000  0.808312  1.000000   \n",
      "2   7.298315    0.015635  0.846303  1.000000   \n",
      "3   7.259959    0.007999  0.870006  1.000000   \n",
      "4   7.161735    0.015642  0.880412  1.000000   \n",
      "\n",
      "   test_neg_root_mean_squared_error  train_neg_root_mean_squared_error  \\\n",
      "0                        -19.685515                      -3.357601e-13   \n",
      "1                        -18.606448                      -2.316268e-13   \n",
      "2                        -26.504671                      -3.712677e-13   \n",
      "3                        -31.053332                      -1.859455e-13   \n",
      "4                        -32.105281                      -2.678098e-13   \n",
      "0                         -9.606428                      -8.052394e+00   \n",
      "1                        -10.141831                      -7.783110e+00   \n",
      "2                        -10.604131                      -7.842056e+00   \n",
      "3                        -10.799221                      -7.710063e+00   \n",
      "4                        -10.182488                      -8.349606e+00   \n",
      "0                         -8.733946                      -3.455872e+00   \n",
      "1                        -10.219525                      -3.389607e+00   \n",
      "2                         -9.447714                      -3.580794e+00   \n",
      "3                         -9.246699                      -3.465005e+00   \n",
      "4                         -8.222717                      -3.604577e+00   \n",
      "0                        -12.627865                      -0.000000e+00   \n",
      "1                        -12.378466                      -0.000000e+00   \n",
      "2                        -12.583307                      -0.000000e+00   \n",
      "3                        -12.673699                      -0.000000e+00   \n",
      "4                        -10.639017                      -0.000000e+00   \n",
      "0                        -15.018765                      -1.504949e+01   \n",
      "1                        -15.197015                      -1.475994e+01   \n",
      "2                        -15.467985                      -1.434549e+01   \n",
      "3                        -17.400392                      -1.514402e+01   \n",
      "4                        -12.879021                      -1.484138e+01   \n",
      "0                         -8.278991                      -6.813960e+00   \n",
      "1                        -12.276110                      -6.285929e+00   \n",
      "2                         -9.111590                      -6.730048e+00   \n",
      "3                        -11.625528                      -6.125240e+00   \n",
      "4                        -11.638133                      -6.724769e+00   \n",
      "0                        -12.627865                      -0.000000e+00   \n",
      "1                        -12.378466                      -0.000000e+00   \n",
      "2                        -12.583307                      -0.000000e+00   \n",
      "3                        -12.673699                      -0.000000e+00   \n",
      "4                        -10.639017                      -0.000000e+00   \n",
      "0                        -10.162439                      -4.426882e-04   \n",
      "1                        -11.607405                      -3.870145e-04   \n",
      "2                        -10.854341                      -3.717752e-04   \n",
      "3                        -10.226334                      -3.880662e-04   \n",
      "4                         -8.655075                      -4.188878e-04   \n",
      "\n",
      "   test_neg_mean_absolute_error  train_neg_mean_absolute_error  \\\n",
      "0                    -10.743816                  -2.456400e-13   \n",
      "1                    -11.850072                  -1.805713e-13   \n",
      "2                    -13.882731                  -2.727083e-13   \n",
      "3                    -14.737374                  -1.331684e-13   \n",
      "4                    -16.853579                  -1.900952e-13   \n",
      "0                     -6.744948                  -6.003425e+00   \n",
      "1                     -7.143121                  -5.376988e+00   \n",
      "2                     -7.478549                  -5.827912e+00   \n",
      "3                     -7.724546                  -5.519109e+00   \n",
      "4                     -6.686008                  -6.094296e+00   \n",
      "0                     -5.052963                  -2.150094e+00   \n",
      "1                     -6.493019                  -1.826995e+00   \n",
      "2                     -5.366792                  -2.067746e+00   \n",
      "3                     -5.415472                  -2.034366e+00   \n",
      "4                     -4.849623                  -2.079484e+00   \n",
      "0                     -6.759259                  -0.000000e+00   \n",
      "1                     -7.301887                  -0.000000e+00   \n",
      "2                     -6.679245                  -0.000000e+00   \n",
      "3                     -7.150943                  -0.000000e+00   \n",
      "4                     -5.603774                  -0.000000e+00   \n",
      "0                     -9.459481                  -9.830375e+00   \n",
      "1                    -10.615105                  -9.313827e+00   \n",
      "2                     -9.649222                  -9.391111e+00   \n",
      "3                    -12.110750                  -9.532850e+00   \n",
      "4                     -8.406837                  -9.634050e+00   \n",
      "0                     -5.187938                  -4.474728e+00   \n",
      "1                     -8.414773                  -4.086590e+00   \n",
      "2                     -6.280756                  -4.400591e+00   \n",
      "3                     -7.441379                  -3.841299e+00   \n",
      "4                     -6.789644                  -4.507451e+00   \n",
      "0                     -6.759259                  -0.000000e+00   \n",
      "1                     -7.301887                  -0.000000e+00   \n",
      "2                     -6.679245                  -0.000000e+00   \n",
      "3                     -7.150943                  -0.000000e+00   \n",
      "4                     -5.603774                  -0.000000e+00   \n",
      "0                     -5.454834                  -2.951082e-04   \n",
      "1                     -7.154982                  -2.843382e-04   \n",
      "2                     -6.033135                  -2.414721e-04   \n",
      "3                     -5.595929                  -2.333950e-04   \n",
      "4                     -4.624418                  -2.695003e-04   \n",
      "\n",
      "           Algorithm Sequence Representation Method  \n",
      "0  Linear regression                          ESM1b  \n",
      "1  Linear regression                          ESM1b  \n",
      "2  Linear regression                          ESM1b  \n",
      "3  Linear regression                          ESM1b  \n",
      "4  Linear regression                          ESM1b  \n",
      "0              LASSO                          ESM1b  \n",
      "1              LASSO                          ESM1b  \n",
      "2              LASSO                          ESM1b  \n",
      "3              LASSO                          ESM1b  \n",
      "4              LASSO                          ESM1b  \n",
      "0      Random Forest                          ESM1b  \n",
      "1      Random Forest                          ESM1b  \n",
      "2      Random Forest                          ESM1b  \n",
      "3      Random Forest                          ESM1b  \n",
      "4      Random Forest                          ESM1b  \n",
      "0    Elastic Network                          ESM1b  \n",
      "1    Elastic Network                          ESM1b  \n",
      "2    Elastic Network                          ESM1b  \n",
      "3    Elastic Network                          ESM1b  \n",
      "4    Elastic Network                          ESM1b  \n",
      "0                SVR                          ESM1b  \n",
      "1                SVR                          ESM1b  \n",
      "2                SVR                          ESM1b  \n",
      "3                SVR                          ESM1b  \n",
      "4                SVR                          ESM1b  \n",
      "0     Neural Network                          ESM1b  \n",
      "1     Neural Network                          ESM1b  \n",
      "2     Neural Network                          ESM1b  \n",
      "3     Neural Network                          ESM1b  \n",
      "4     Neural Network                          ESM1b  \n",
      "0    Elastic Network                          ESM1b  \n",
      "1    Elastic Network                          ESM1b  \n",
      "2    Elastic Network                          ESM1b  \n",
      "3    Elastic Network                          ESM1b  \n",
      "4    Elastic Network                          ESM1b  \n",
      "0            XGBoost                          ESM1b  \n",
      "1            XGBoost                          ESM1b  \n",
      "2            XGBoost                          ESM1b  \n",
      "3            XGBoost                          ESM1b  \n",
      "4            XGBoost                          ESM1b  \n"
     ]
    }
   ],
   "source": [
    "summary=[]\n",
    "\n",
    "for method in methods:\n",
    "    dfR = ml_process(method, output , df_kcatKmTopt, aln, esm1b, temp = False)\n",
    "    print(dfR)\n",
    "    summary.append(dfR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc98112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n",
      "C:\\Users\\memre\\AppData\\Local\\Temp\\ipykernel_22720\\1172027454.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result=result.append(summary[item])\n"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame()\n",
    "for item in range(8):\n",
    "    result=result.append(summary[item])\n",
    "result.to_excel(date + 'Predicting Optimum Temperature' + enzyme +'5 CV.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b658105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce163613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['test_root_mean_squared_error']=df_res['test_neg_root_mean_squared_error'].abs()\n",
    "df_res['test_mean_absolute_error']=df_res['test_neg_mean_absolute_error'].abs()\n",
    "\n",
    "df_res['train_root_mean_squared_error']=df_res['train_neg_root_mean_squared_error'].abs()\n",
    "df_res['train_mean_absolute_error']=df_res['train_neg_mean_absolute_error'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e2c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res=df_res.groupby(['Algorithm', 'Sequence Representation Method'], as_index=False).agg({'test_r2':['mean','std'],\n",
    "                                                                                             'test_root_mean_squared_error':['mean','std'],\n",
    "                                                                                             'test_mean_absolute_error':['mean','std'],\n",
    "                                                                                             'train_r2':['mean','std'],\n",
    "                                                                                             'train_root_mean_squared_error':['mean','std'],\n",
    "                                                                                             'train_mean_absolute_error':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf1aec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res.to_excel(date + 'Predicting Optimum Temperature' + enzyme +'5 CV mean and std.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9ff29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b6010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
