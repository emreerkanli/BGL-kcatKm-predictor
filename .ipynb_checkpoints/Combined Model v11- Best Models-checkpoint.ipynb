{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f3aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from Bio import pairwise2\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio.Align.Applications import MuscleCommandline\n",
    "from Bio.Align import AlignInfo\n",
    "import pandascharm as pc\n",
    "\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from Bio.SubsMat.MatrixInfo import blosum45\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f2c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeoutlier_col(df,cols):\n",
    "    Q1 = df[cols].quantile(0.25)\n",
    "    Q3 = df[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_out = df[~((df[[cols]] < (Q1 - 1.5 * IQR)) |(df[[cols]] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bab29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence Representation Methods\n",
    "\n",
    "blosum62.update(((b,a),val) for (a,b),val in list(blosum62.items()))\n",
    "blosum45.update(((b,a),val) for (a,b),val in list(blosum45.items()))\n",
    "\n",
    "def score_pairwise(seq1, seq2, matrix, gap_s, gap_e, gap = True):\n",
    "    for A,B in zip(seq1, seq2):\n",
    "        diag = ('-'==A) or ('-'==B)\n",
    "        yield (gap_e if gap else gap_s) if diag else matrix[(A,B)]\n",
    "        gap = diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e70a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(encoding, output, df_clean, aln, esm1b ,key = None):\n",
    "    \n",
    "    df_clean = df_clean.set_index('Index')\n",
    "    \n",
    "    ClustalAlign = AlignIO.read(aln, 'clustal')\n",
    "    summary_align = AlignInfo.SummaryInfo(ClustalAlign )\n",
    "    dframe = pc.from_bioalignment(ClustalAlign).transpose()\n",
    "    sequences = dframe.loc[df_clean.index]\n",
    "    \n",
    "    y = df_clean[output]\n",
    "\n",
    "    if encoding == 'One_Hot_Encoder':\n",
    "\n",
    "        one_hot = OneHotEncoder()\n",
    "        encoded = one_hot.fit(sequences)\n",
    "        X = encoded.transform(sequences).toarray()\n",
    "\n",
    "           \n",
    "    if encoding == 'Bag_of_Words':\n",
    "\n",
    "        X = pd.DataFrame([ProteinAnalysis(i).count_amino_acids() for i in df_clean['Sequence']])\n",
    "        X = np.array(X)\n",
    "        \n",
    "    if encoding == 'bigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                st = i+j\n",
    "                all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-1):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "    \n",
    "    if encoding == 'trigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    st = i+j+k\n",
    "                    all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-2):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "\n",
    "        \n",
    "    if encoding == 'quadrogram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    for l in lst:\n",
    "                        st = i+j+k+l\n",
    "                        all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-3):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]+temp[k+3]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.array(X)\n",
    "\n",
    "\n",
    "    if encoding == 'BLOSUM62':\n",
    "\n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum62, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "\n",
    "        X = np.array(enc_seq)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    if encoding == 'BLOSUM45':\n",
    "        \n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum45, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "        X = np.array(enc_seq)\n",
    "      \n",
    "        \n",
    "    if encoding == 'ESM1b':\n",
    "\n",
    "        encoded = esm1b.loc[df_clean.index]\n",
    "        X = np.array(encoded)\n",
    "\n",
    "        \n",
    "    return X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequence Representation Methods with Temperature\n",
    "\n",
    "def encode_temp(encoding, output, df_clean, aln, esm1b , temperature):\n",
    "    \n",
    "    df_clean = df_clean.set_index('Index')\n",
    "    \n",
    "    ClustalAlign = AlignIO.read(aln, 'clustal')\n",
    "    summary_align = AlignInfo.SummaryInfo(ClustalAlign )\n",
    "    dframe = pc.from_bioalignment(ClustalAlign).transpose()\n",
    "    sequences = dframe.loc[df_clean.index]\n",
    "    \n",
    "    y = df_clean['Percentage Activity Depending on Optimum Temp']\n",
    "\n",
    "\n",
    "    if encoding == 'One_Hot_Encoder':\n",
    "\n",
    "        one_hot = OneHotEncoder()\n",
    "        encoded = one_hot.fit(sequences)\n",
    "        sequences_encoded = encoded.transform(sequences).toarray()\n",
    "        X = np.concatenate((sequences_encoded,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "           \n",
    "    if encoding == 'Bag_of_Words':\n",
    "\n",
    "        X = pd.DataFrame([ProteinAnalysis(i).count_amino_acids() for i in df_clean['Sequence']])\n",
    "        X = np.concatenate((X,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "    if encoding == 'bigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                st = i+j\n",
    "                all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-1):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.concatenate((X,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "    \n",
    "    if encoding == 'trigram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    st = i+j+k\n",
    "                    all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-2):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        X = np.concatenate((X,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "        \n",
    "    if encoding == 'quadrogram':\n",
    "        \n",
    "        X = df_clean['Sequence']\n",
    "\n",
    "        example = df_clean['Sequence'][0]\n",
    "        lst = ['E','G','L','Y','T','H','R','A','C','D','P','I','F','N','K','S','V','M','W','Q']\n",
    "        all_dct = {}\n",
    "        key = []\n",
    "        for i in lst:\n",
    "            for j in lst:\n",
    "                for k in lst:\n",
    "                    for l in lst:\n",
    "                        st = i+j+k+l\n",
    "                        all_dct[st] = []\n",
    "\n",
    "        for example, id in zip(X,range(len(X))):\n",
    "\n",
    "            temp = list(example)\n",
    "            temp_dct = dict.fromkeys(all_dct.keys(),0)\n",
    "            for k in range(len(temp)-3):\n",
    "                try:\n",
    "                    check = temp[k] + temp[k+1]+temp[k+2]+temp[k+3]\n",
    "                    temp_dct[check] += 1\n",
    "                except:\n",
    "                    pass\n",
    "            for key, value in temp_dct.items():\n",
    "                all_dct[key].append(value)\n",
    "                \n",
    "        X = pd.DataFrame.from_dict(all_dct).set_index(df_clean.index)\n",
    "        \n",
    "        X = np.concatenate((X,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "    if encoding == 'BLOSUM62':\n",
    "\n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum62, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "\n",
    "        X = np.concatenate((enc_seq,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "    if encoding == 'BLOSUM45':\n",
    "        \n",
    "        n = len(sequences)\n",
    "        enc_seq = np.zeros((n,n))\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for a in list(sequences.index):\n",
    "            j = 0\n",
    "            for b in list(sequences.index):\n",
    "                enc_seq[i,j] = sum(score_pairwise(sequences.loc[a], sequences.loc[b], blosum45, -5, -1))\n",
    "                j += 1\n",
    "            i += 1\n",
    "\n",
    "        X = np.concatenate((enc_seq,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "    if encoding == 'ESM1b':\n",
    "        \n",
    "\n",
    "        encoded = esm1b.loc[df_clean.index]\n",
    "        X = np.concatenate((encoded,df_clean[[temperature]]), axis =1)\n",
    "\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_algorithm(algorithm, X_train, y_train, X_val):\n",
    "\n",
    "    if algorithm == 'Random Forest':\n",
    "\n",
    "        model = RandomForestRegressor(random_state = 42)\n",
    "        model.fit(X_train,np.ravel(y_train))\n",
    "        prediction = model.predict(X_val)\n",
    "\n",
    "\n",
    "    if algorithm == 'XGBoost':\n",
    "\n",
    "        model = xgb.XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "            \n",
    "    if algorithm == 'LASSO':\n",
    "\n",
    "        model = Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "        \n",
    "    if algorithm == 'SVR':\n",
    "\n",
    "        model =  SVR()\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "\n",
    "    if algorithm == 'Neural Network':\n",
    "        \n",
    "        model = MLPRegressor(random_state=101, max_iter=100)\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "        \n",
    "    if algorithm == 'Elastic Net':\n",
    "        \n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_val)\n",
    "        \n",
    "    return model, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbacbcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme = 'betaGlucosidasewithMutants'\n",
    "\n",
    "df = pd.read_excel('betaGlucosidasewithMutantsOptimumTemperature.xlsx')\n",
    "\n",
    "output = 'pNP-Glc kcat/Km (1/smM)'\n",
    "aln = enzyme + '.aln'\n",
    "\n",
    "x = datetime.datetime.now()\n",
    "date = str(x.year)+str(x.month)+str(x.day)\n",
    "\n",
    "df['Log'+output] = np.log10(df[output])\n",
    "esm1b = pd.read_excel(enzyme+'ESM1b_embeddings.xlsx', index_col = 0)\n",
    "\n",
    "random_state = [202 , 1, 42, 101, 2022,5 , 10, 22, 1995, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [[['XGBoost', 'ESM1b'],['SVR', 'ESM1b'], ['Random Forest', 'Bag_of_Words']],\n",
    "             [['XGBoost', 'ESM1b'],['SVR', 'ESM1b'], ['Random Forest', 'BLOSUM45']],\n",
    "             [['Random Forest', 'Bag_of_Words'],['SVR', 'ESM1b'], ['Elastic Net','quadrogram']],\n",
    "             [['Random Forest', 'Bag_of_Words'],['SVR', 'ESM1b'], ['Elastic Net','trigram']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25759482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Function to save model\n",
    "def save_model(model, model_name):\n",
    "    joblib.dump(model, f'{model_name}.joblib')\n",
    "\n",
    "# Function to load model\n",
    "def load_model(model_name):\n",
    "    return joblib.load(f'{model_name}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9903676",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_final_results = []\n",
    "list_df_val = []\n",
    "combinations =[]\n",
    "list_predicted_optimum_temperature = []\n",
    "list_predicted_maximum_activity = []\n",
    "list_predicted_relative_activity = []\n",
    "\n",
    "\n",
    "list_final_results_train = []\n",
    "list_df_train = []\n",
    "list_predicted_optimum_temperature_train = []\n",
    "list_predicted_maximum_activity_train = []\n",
    "list_predicted_relative_activity_train = []\n",
    "\n",
    "\n",
    "for state in random_state:\n",
    "    \n",
    "    for models in model_list:\n",
    "        \n",
    "        model_1_list= [models[0]]\n",
    "        model_2_list= [models[1]]\n",
    "        model_3_list= [models[2]]\n",
    "        \n",
    "        df['Relative Temperature'] = df['Reaction Temperature'] - df[\"Temperature Optimum\"]\n",
    "\n",
    "        df_clean = removeoutlier_col(df,'Log' + output).reset_index()\n",
    "\n",
    "        # Create a mapping of unique sequences to unique codes\n",
    "        sequence_to_code = {seq: f\"ENZYME_{i+1}\" for i, seq in enumerate(df_clean['Sequence'].unique())}\n",
    "\n",
    "        # Map these codes to a new column in the DataFrame using .loc\n",
    "        df_clean.loc[:, 'Sequence Code'] = df_clean['Sequence'].map(sequence_to_code)\n",
    "\n",
    "        splitter = GroupShuffleSplit(test_size=.20, n_splits=10, random_state = state)\n",
    "\n",
    "        split = splitter.split(df_clean, groups=df_clean['Sequence Code'])\n",
    "\n",
    "        train_inds, val_inds = next(split)\n",
    "\n",
    "        train_inds_unique = df_clean.iloc[train_inds][df_clean.iloc[train_inds]['Percentage Activity Depending on Optimum Temp']==1].index\n",
    "\n",
    "        val_inds_unique = df_clean.iloc[val_inds][df_clean.iloc[val_inds]['Percentage Activity Depending on Optimum Temp']==1].index\n",
    "\n",
    "\n",
    "\n",
    "        X_ESM1b  = encode('ESM1b', 'Temperature Optimum', df_clean, aln, esm1b)\n",
    "        X_BLOSUM45 = encode('BLOSUM45', 'Temperature Optimum', df_clean, aln, esm1b)\n",
    "        X_trigram  = encode('trigram', 'Temperature Optimum', df_clean, aln, esm1b)\n",
    "        X_quadrogram  = encode('quadrogram', 'Temperature Optimum', df_clean, aln, esm1b)\n",
    "        X_Bag_of_Words  = encode('Bag_of_Words', 'Temperature Optimum', df_clean, aln, esm1b)\n",
    "\n",
    "        sequence_dictionary = {'ESM1b': X_ESM1b,'BLOSUM45': X_BLOSUM45,'trigram' : X_trigram,'quadrogram': X_quadrogram, \n",
    "       'Bag_of_Words' : X_Bag_of_Words}\n",
    "    \n",
    "\n",
    "        for model1_algorithm, model1_method  in model_1_list:\n",
    "            model_name_1 = f'{model1_method}_{model1_algorithm}_optimum_temperature_state_{state}'\n",
    "            model_1 = load_model(model_name_1)\n",
    "\n",
    "            X_val_temperature = sequence_dictionary[model1_method][val_inds]\n",
    "            X_train_temperature = sequence_dictionary[model1_method][train_inds]\n",
    "\n",
    "            if model1_algorithm in ['LASSO', 'SVR', 'Neural Network']:\n",
    "                scaler = preprocessing.StandardScaler()\n",
    "                scaler.fit(sequence_dictionary[model1_method])\n",
    "                X_val_temperature = scaler.transform(X_val_temperature)\n",
    "                X_train_temperature = scaler.transform(X_train_temperature) \n",
    "\n",
    "            prediction_Topt = model_1.predict(X_val_temperature)\n",
    "            predict_train_Topt = model_1.predict(X_train_temperature)\n",
    "            \n",
    "\n",
    "            for model2_algorithm, model2_method  in model_2_list:\n",
    "                model_name_2 = f'{model2_method}_{model2_algorithm}_maximum_activity_state_{state}'\n",
    "                model_2 = load_model(model_name_2)\n",
    "\n",
    "                X_val_activity = sequence_dictionary[model2_method][val_inds]\n",
    "                X_train_activity = sequence_dictionary[model2_method][train_inds]\n",
    "                \n",
    "\n",
    "                if model2_algorithm in ['LASSO', 'SVR', 'Neural Network']:\n",
    "                    scaler = preprocessing.StandardScaler()\n",
    "                    scaler.fit(sequence_dictionary[model2_method])\n",
    "\n",
    "                    X_val_activity  = scaler.transform(X_val_activity) \n",
    "                    X_train_activity = scaler.transform(X_train_activity)\n",
    "\n",
    "                prediction_MaxActivity = model_2.predict(X_val_activity)\n",
    "                prediction_train_MaxActivity = model_2.predict(X_train_activity)\n",
    "\n",
    "\n",
    "                for model3_algorithm, model3_method in model_3_list: \n",
    "                    model_name_3 = f'{model3_method}_{model3_algorithm}_temperature_profile_state_{state}'\n",
    "                    model_3 = load_model(model_name_3)\n",
    "\n",
    "                    df_val = df_clean.iloc[val_inds]\n",
    "                    y_val_activity = df_val['Log' +'pNP-Glc kcat/Km (1/smM)']\n",
    "                    \n",
    "                    df_train = df_clean.iloc[train_inds]\n",
    "                    y_train_activity = df_train['Log' +'pNP-Glc kcat/Km (1/smM)']\n",
    "\n",
    "                    relative_temperature = prediction_Topt- df_val['Reaction Temperature'].values\n",
    "                    relative_temperature_train = predict_train_Topt- df_train['Reaction Temperature'].values\n",
    "                    \n",
    "                    X_val = np.concatenate((sequence_dictionary[model3_method][val_inds], relative_temperature.reshape(-1, 1)), axis=1)\n",
    "                    X_train = np.concatenate((sequence_dictionary[model3_method][train_inds], relative_temperature_train.reshape(-1, 1)), axis=1)\n",
    "                    \n",
    "                    \n",
    "                    y_val_predicted = model_3.predict(X_val)\n",
    "                    y_val_predicted[y_val_predicted < 0] = 0.01\n",
    "                    \n",
    "                    y_train_predicted = model_3.predict(X_train)\n",
    "                    y_train_predicted[y_train_predicted < 0] = 0.01\n",
    "\n",
    "                    results = np.log10(y_val_predicted * (10**prediction_MaxActivity))\n",
    "                    results_train = np.log10(y_train_predicted * (10**prediction_train_MaxActivity))\n",
    "\n",
    "\n",
    "                    df_val['Log Predicted kcat/Km'] = results\n",
    "                    df_val['Predicted kcat/Km'] = 10**results\n",
    "                    \n",
    "                    df_train['Log Predicted kcat/Km'] = results_train\n",
    "                    df_train['Predicted kcat/Km'] = 10**results_train\n",
    "\n",
    "                    list_predicted_relative_activity.append(y_val_predicted)\n",
    "                    list_final_results.append(results)\n",
    "                    \n",
    "                    list_df_val.append(df_val)\n",
    "                    list_predicted_optimum_temperature.append(prediction_Topt)\n",
    "                    list_predicted_maximum_activity.append(prediction_MaxActivity)\n",
    "\n",
    "                    list_predicted_relative_activity_train.append(y_train_predicted)\n",
    "                    list_final_results_train.append(results_train)\n",
    "                    \n",
    "                    list_df_train.append(df_train)\n",
    "                    list_predicted_optimum_temperature_train.append(predict_train_Topt)\n",
    "                    list_predicted_maximum_activity_train.append(prediction_train_MaxActivity)                    \n",
    "                    \n",
    "                    combination = 'Model 1:'+ model1_method + ' with ' + model1_algorithm + ', and ' +  'Model 2:'+ model2_method + ' with ' + model2_algorithm + ', and ' + 'Model 3:'+ model3_method +' with ' + model3_algorithm + '_'+ str(state)\n",
    "\n",
    "                    combinations.append(combination)\n",
    "                    \n",
    "                    print(combination)\n",
    "                    print(str(state))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ed596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "date = str(x.year)+str(x.month)+str(x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_optimum_temperature = pd.DataFrame(list_predicted_optimum_temperature, index = combinations).transpose()\n",
    "df_predicted_maximum_activity = pd.DataFrame(list_predicted_maximum_activity, index = combinations).transpose()\n",
    "df_predicted_relative_activity = pd.DataFrame(list_predicted_relative_activity, index = combinations).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_optimum_temperature_train = pd.DataFrame(list_predicted_optimum_temperature_train, index = combinations).transpose()\n",
    "df_predicted_maximum_activity_train = pd.DataFrame(list_predicted_maximum_activity_train, index = combinations).transpose()\n",
    "df_predicted_relative_activity_train = pd.DataFrame(list_predicted_relative_activity_train, index = combinations).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416433bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_predicted_optimum_temperature.to_excel(date +  ' Predicted Optimum Temperature y_val values 3 Models Combined.xlsx')\n",
    "\n",
    "df_predicted_maximum_activity.to_excel(date +  ' Predicted Maximum Activity y_val values Models 3 Combined.xlsx')\n",
    "\n",
    "df_predicted_relative_activity.to_excel(date +  ' Predicted Relative Activity y_val values Models 3 Combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_predicted_optimum_temperature_train.to_excel(date +  ' Predicted Training Optimum Temperature y_val values 3 Models Combined.xlsx')\n",
    "\n",
    "df_predicted_maximum_activity_train.to_excel(date +  ' Predicted Training Maximum Activity y_val values Models 3 Combined.xlsx')\n",
    "\n",
    "df_predicted_relative_activity_train.to_excel(date + ' Predicted Training Relative Activity y_val values Models 3 Combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d11888",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5', 'Trial 6', 'Trial 7', 'Trial 8', 'Trial 9', 'Trial 10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = combinations[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5af22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_train_predicted_activity = {}\n",
    "i = 0\n",
    "for name in names:\n",
    "    list_df_train_predicted_activity[name] = pd.DataFrame(list_final_results_train[:][i:i+4], index = column_names).transpose()\n",
    "    i = i + 4\n",
    "    \n",
    "    \n",
    "list_df_predicted_activity = {}\n",
    "i = 0\n",
    "for name in names:\n",
    "    list_df_predicted_activity[name] = pd.DataFrame(list_final_results[:][i:i+4], index = column_names).transpose()\n",
    "    i = i + 4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the output Excel file name\n",
    "output_file = '20241219 kcatKm prediction betaGlucosidase - y_val values predicted - 3 Models combined.xlsx'\n",
    "\n",
    "# Write each dataframe to a separate sheet in the Excel workbook\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in list_df_predicted_activity.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the output Excel file name\n",
    "output_file = '20241219 kcatKm prediction betaGlucosidase - y_train values predicted - 3 Models combined.xlsx'\n",
    "\n",
    "# Write each dataframe to a separate sheet in the Excel workbook\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    for sheet_name, df in list_df_train_predicted_activity.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_excel('20241219 kcatKm prediction betaGlucosidase - y_val values predicted - 3 Models combined.xlsx', sheet_name= names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel('20241219 kcatKm prediction betaGlucosidase - y_train values predicted - 3 Models combined.xlsx', sheet_name=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting y-val values\n",
    "y_val_list = []\n",
    "y_train_list = []\n",
    "train_ind_list = []\n",
    "val_ind_list = []\n",
    "\n",
    "for state in random_state:\n",
    "    df_clean = removeoutlier_col(df,'Log' + output).reset_index()\n",
    "\n",
    "    # Create a mapping of unique sequences to unique codes\n",
    "    sequence_to_code = {seq: f\"ENZYME_{i+1}\" for i, seq in enumerate(df_clean['Sequence'].unique())}\n",
    "\n",
    "    # Map these codes to a new column in the DataFrame using .loc\n",
    "    df_clean.loc[:, 'Sequence Code'] = df_clean['Sequence'].map(sequence_to_code)\n",
    "\n",
    "    splitter = GroupShuffleSplit(test_size=.20, n_splits=10, random_state = state)\n",
    "\n",
    "    split = splitter.split(df_clean, groups=df_clean['Sequence Code'])\n",
    "\n",
    "    train_inds, val_inds = next(split)\n",
    "    \n",
    "    y_val_list.append(df_clean.iloc[val_inds]['Log'+output].values)\n",
    "    y_train_list.append(df_clean.iloc[train_inds]['Log'+output].values)\n",
    "    train_ind_list.append(train_inds)\n",
    "    val_ind_list.append(val_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name in names:\n",
    "    df_val[name]['y value'] = y_val_list[i]\n",
    "    df_train[name]['y value'] = y_train_list[i]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62359fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Training and Validation\n",
    "list_df_entire_predicted_activity = {}\n",
    "\n",
    "for i in names:  # Iterate over each split\n",
    "    combined_df = pd.concat([df_train[i], df_val[i]])  # Keep original indices\n",
    "    list_df_entire_predicted_activity[i] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717fd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [df_val , df_train, list_df_entire_predicted_activity]\n",
    "dataset_types = [\"Validation\", \"Training\", \"Entire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric lists for storing results\n",
    "list_R2_df = []\n",
    "list_RMSE_df = []\n",
    "list_MAE_df = []\n",
    "list_PCC_df = []\n",
    "list_pValue_df = []\n",
    "\n",
    "i =1\n",
    "\n",
    "# Process each dataset (validation, training, entire)\n",
    "for data, dataset_type in zip(data_set, dataset_types):\n",
    "    list_R2, list_RMSE, list_MAE, list_PCC, list_pValue = [], [], [], [], []\n",
    "\n",
    "    # Loop through each split in the dataset dictionary\n",
    "    for state_key in data:\n",
    "        state = data[state_key]  # Access the DataFrame\n",
    "\n",
    "        r2_list, rmse_list, mae_list, pcc_list, pvalue_list = [], [], [], [], []\n",
    "\n",
    "        # Calculate metrics for each model in the dataframe\n",
    "        for model in state.columns[:-1]:  # Assuming 'y_val' is the last column\n",
    "            r2 = r2_score(state['y value'], state[model])\n",
    "            rmse = mean_squared_error(state['y value'], state[model], squared=False)\n",
    "            mae = mean_absolute_error(state['y value'], state[model])\n",
    "            pcc, pValue = pearsonr(state['y value'], state[model])\n",
    "\n",
    "            r2_list.append(r2)\n",
    "            rmse_list.append(rmse)\n",
    "            mae_list.append(mae)\n",
    "            pcc_list.append(pcc)\n",
    "            pvalue_list.append(pValue)\n",
    "\n",
    "        # Append results for this split\n",
    "        list_R2.append(r2_list)\n",
    "        list_RMSE.append(rmse_list)\n",
    "        list_MAE.append(mae_list)\n",
    "        list_PCC.append(pcc_list)\n",
    "        list_pValue.append(pvalue_list)\n",
    "        \n",
    "    column_names = state.columns[:-1]\n",
    "\n",
    "    # Convert metric lists to DataFrames for each split\n",
    "    Results_R2 = pd.DataFrame(list_R2, columns=column_names, index = names)\n",
    "    Results_RMSE = pd.DataFrame(list_RMSE, columns=column_names,index = names)\n",
    "    Results_MAE = pd.DataFrame(list_MAE, columns=column_names, index = names)\n",
    "    Results_PCC = pd.DataFrame(list_PCC, columns=column_names, index = names)\n",
    "    Results_pValue = pd.DataFrame(list_pValue, columns=column_names, index = names)\n",
    "\n",
    "    # Append each metric's result DataFrame\n",
    "    list_R2_df.append(Results_R2)\n",
    "    list_RMSE_df.append(Results_RMSE)\n",
    "    list_MAE_df.append(Results_MAE)\n",
    "    list_PCC_df.append(Results_PCC)\n",
    "    list_pValue_df.append(Results_pValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write metrics to Excel file with specified structure\n",
    "def write_metrics_to_excel(filename, metric_dfs, metric_name):\n",
    "    with pd.ExcelWriter(filename) as writer:\n",
    "        # Initialize empty DataFrames for validation, training, and entire dataset results\n",
    "\n",
    "        # Select the first four columns for Validation\n",
    "        validation_df = metric_dfs[0]\n",
    "\n",
    "        # Select the next four columns for Training\n",
    "        training_df = metric_dfs[1]\n",
    "\n",
    "        # Select the last four columns for Entire\n",
    "        entire_df =metric_dfs[2]\n",
    "\n",
    "        # Write each dataset type to a separate sheet\n",
    "        validation_df.to_excel(writer, sheet_name=\"Validation\", index=False)\n",
    "        training_df.to_excel(writer, sheet_name=\"Training\", index=False)\n",
    "        entire_df.to_excel(writer, sheet_name=\"Entire\", index=False)\n",
    "\n",
    "        # Calculate the average across the 10 trials for each dataset type\n",
    "        avg_validation = validation_df.mean(axis=0)\n",
    "        avg_training = training_df.mean(axis=0)\n",
    "        avg_entire = entire_df.mean(axis=0)\n",
    "\n",
    "        \n",
    "        model_names =  validation_df.columns\n",
    "        # Create DataFrames for average values\n",
    "        avg_validation_df = pd.DataFrame(avg_validation, columns=['Average'], index = model_names)\n",
    "        avg_training_df = pd.DataFrame(avg_training, columns=['Average'], index = model_names)\n",
    "        avg_entire_df = pd.DataFrame(avg_entire, columns=['Average'], index = model_names)\n",
    "\n",
    "        # Write average values to separate sheets\n",
    "        avg_validation_df.to_excel(writer, sheet_name=\"Avg_Validation\")\n",
    "        avg_training_df.to_excel(writer, sheet_name=\"Avg_Training\",)\n",
    "        avg_entire_df.to_excel(writer, sheet_name=\"Avg_Entire\")\n",
    "\n",
    "        # Calculate the standard deviation across the 10 trials for each dataset type\n",
    "        std_validation = validation_df.std(axis=0)\n",
    "        std_training = training_df.std(axis=0)\n",
    "        std_entire = entire_df.std(axis=0)\n",
    "\n",
    "        # Create DataFrames for standard deviation values\n",
    "        std_validation_df = pd.DataFrame(std_validation, columns=['Std_Dev'], index = model_names)\n",
    "        std_training_df = pd.DataFrame(std_training, columns=['Std_Dev'], index = model_names)\n",
    "        std_entire_df = pd.DataFrame(std_entire, columns=['Std_Dev'], index = model_names)\n",
    "\n",
    "        # Write standard deviation values to separate sheets\n",
    "        std_validation_df.to_excel(writer, sheet_name=\"Std_Validation\")\n",
    "        std_training_df.to_excel(writer, sheet_name=\"Std_Training\")\n",
    "        std_entire_df.to_excel(writer, sheet_name=\"Std_Entire\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Write each metric to separate Excel files with date in the filename\n",
    "for metric_dfs, metric_name in zip(\n",
    "        [list_R2_df, list_RMSE_df, list_MAE_df, list_PCC_df, list_pValue_df],\n",
    "        [\"R2\", \"RMSE\", \"MAE\", \"PCC\", \"pValue\"]):\n",
    "    filename = f\"{current_date}_{metric_name}_3ModelCombinedResults_.xlsx\"\n",
    "    write_metrics_to_excel(filename, metric_dfs, metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models(y_predicted, y_val, combinations, r2, trial):\n",
    "\n",
    "    #logaritmic scale, Combined Models\n",
    "\n",
    "    sns.set(font_scale=1.5)\n",
    "    from matplotlib import ticker as mticker\n",
    "\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "    plt.rcParams['axes.linewidth'] =  5\n",
    "    plt.rcParams['ytick.major.width'] =  4\n",
    "    plt.rcParams['ytick.minor.width'] =  2\n",
    "    plt.rcParams['xtick.major.width'] =  4\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "    sns.scatterplot(y=y_predicted, x = y_val, s=200)\n",
    "\n",
    "\n",
    "    ax.set(xlabel=\"Reported $k$$_{\\\\rm cat}$/$K$$_{\\\\rm m}$ (mM$^{-1}$s$^{-1}$)\",\n",
    "       ylabel= \"Predicted $k$$_{\\\\rm cat}$/$K$$_{\\\\rm m}$ (mM$^{-1}$s$^{-1}$)\")\n",
    "\n",
    "    ax.yaxis.set_major_formatter(mticker.StrMethodFormatter(\"$10^{{{x:.0f}}}$\"))\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    tick_range = np.arange(ymin, ymax)\n",
    "    ax.yaxis.set_ticks([np.log10(y) for p in tick_range for y in np.linspace(10 ** p, 10 ** (p + 1), 10)], minor=True)\n",
    "\n",
    "\n",
    "    ax.xaxis.set_major_formatter(mticker.StrMethodFormatter(\"$10^{{{x:.0f}}}$\"))\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    tick_range = np.arange(xmin, xmax)\n",
    "    ax.xaxis.set_ticks([np.log10(x) for p in tick_range for x in np.linspace(10 ** p, 10 ** (p + 1), 10)], minor=True)\n",
    "\n",
    "\n",
    "\n",
    "    val_range=[min(ymin, xmin),max(ymax,xmax)]  \n",
    "\n",
    "    plt.xlim(val_range)\n",
    "    plt.ylim(val_range)\n",
    "    plt.title(combinations + ' ' + trial +' R2 value: ' + str(round(r2,3)), pad =40)\n",
    "\n",
    "    plt.plot(val_range, val_range, '--k')\n",
    "    plt.savefig(date +' SingleLayerModel '+ trial + ' ' + combinations + '.png',  bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reaction_analyzer(sequence, df, model, df_predicted_optimum_temperature,r2, trial):\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.set_style(\"ticks\")\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "    plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "    plt.rcParams['axes.linewidth'] = 5\n",
    "    plt.rcParams['ytick.major.width'] = 4\n",
    "    plt.rcParams['ytick.minor.width'] = 2\n",
    "    plt.rcParams['xtick.major.width'] = 4\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    df['Name'] = df['Organism Name Actual'] + ' (' + df['Mutation'].fillna('') + ')'\n",
    "    organism_name = df[df['Sequence'] == sequence]['Name'].unique()\n",
    "\n",
    "    # Scatter plots\n",
    "    scatter1 = sns.scatterplot(data=df[df['Sequence'] == sequence], y='pNP-Glc kcat/Km (1/smM)', x='Reaction Temperature', marker=\"o\", s=400, color=\"blue\", ax=ax1)\n",
    "    \n",
    "    scatter2 = sns.scatterplot(data=df[df['Sequence'] == sequence], y=model, x='Reaction Temperature', marker=\"^\", s=400, color=\"red\", ax=ax2)\n",
    "    ax1.set_title(model +\"\\n\" + organism_name[0] + 'R2: '+ str(r2) + ', '+trial, pad =40)\n",
    "    \n",
    "    \n",
    "    ax1.set_xlabel(\"Reaction Temperature ($^\\circ$C)\")\n",
    "    ax1.set_ylabel('Reported $k$$_{\\\\rm cat}$/$K$$_{\\\\rm m}$ (mM$^{-1}$s$^{-1}$)', color='b')\n",
    "    ax2.set_ylabel('Predicted $k$$_{\\\\rm cat}$/$K$$_{\\\\rm m}$ (mM$^{-1}$s$^{-1}$)', color='r')\n",
    "\n",
    "    ymin1, ymax1 = ax1.get_ylim()\n",
    "    ymin2, ymax2 = ax2.get_ylim()\n",
    "    training_range = [ymin1 , ymax1]\n",
    "\n",
    "#    optimum_temperature = np.mean(df[df['Sequence'] == sequence]['Temperature Optimum'])\n",
    "#    ax1.plot([optimum_temperature, optimum_temperature], training_range, '--b', label='Optimum Temperature')\n",
    "\n",
    "#    predicted_optimum_temperature = np.mean(df_predicted_optimum_temperature[df_predicted_optimum_temperature['Sequence'] == sequence][model])\n",
    "#    ax1.plot([predicted_optimum_temperature, predicted_optimum_temperature], training_range, '--r', label='Predicted Optimum Temperature')\n",
    "\n",
    "    # Create dummy legend handles for scatter plots\n",
    "    from matplotlib.lines import Line2D\n",
    "    handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Reported kcat/Km'),\n",
    "        Line2D([0], [0], marker='^', color='w', markerfacecolor='red', markersize=10, label='Predicted kcat/Km')\n",
    "    ]\n",
    "\n",
    "    # Get other legend handles and labels from the plots\n",
    "    handles1, labels1 = ax1.get_legend_handles_labels()\n",
    "    handles.extend(handles1)\n",
    "    handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "    handles.extend(handles2)\n",
    "\n",
    "    labels = ['Reported kcat/Km', 'Predicted kcat/Km'] + labels1 + labels2\n",
    "\n",
    "    ax1.legend(handles, labels, loc='upper left', bbox_to_anchor=(1.1, 1))\n",
    "    name_organism = organism_name[0].replace('/', ',')\n",
    "    plt.savefig('C:\\\\Users\\\\memre\\\\Desktop\\\\Sequence\\\\' + \n",
    "                model_name.replace(':', '').replace(' ', '').replace(',', '').replace('_', '').replace(':', '').replace('Model', '') \n",
    "                + trial + name_organism.replace(' ', '') \n",
    "                + '.png',  bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = df_val['Trial 1'].columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for trial in df_val:\n",
    "    for model in model_name_list:\n",
    "        r2 = r2_score(df_val[trial]['y value'].values, df_val[trial][model].values)\n",
    "        plot_models(df_val[trial][model].values, df_val[trial]['y value'].values, model.replace(':', '').replace(' ', ''), r2 ,trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804369f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for trial in  df_val:\n",
    "    for model_name in model_name_list:\n",
    "        df_model = df_val[trial][[model_name, 'y value']]\n",
    "        r2 = r2_score(df_model ['y value'], df_model[model_name])\n",
    "        r2 = (round(r2, 2))\n",
    "\n",
    "        df_plotting = df_clean.iloc[val_ind_list[i]]\n",
    "        df_plotting[model_name] = 10**df_val[trial][model_name].values\n",
    "        \n",
    "        sequence_list = df_plotting['Sequence'].unique()\n",
    "        for seq in sequence_list:\n",
    "            df_temperature_plotting=np.nan\n",
    "            reaction_analyzer(seq, df_plotting, model_name, df_temperature_plotting,r2, trial)\n",
    "            \n",
    "    i = i + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb00cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
